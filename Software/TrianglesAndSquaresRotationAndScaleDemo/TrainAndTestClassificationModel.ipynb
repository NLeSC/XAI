{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for classification of triangles vs. squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from code import shape_images as shi\n",
    "from code import model as mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of pre-generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "# data paths\n",
    "original_data_path = \"/home/elena/eStep/XAI/Data/TrianglesAndSquaresRotationScale\"\n",
    "\n",
    "train_data_fname = os.path.join(original_data_path, 'split_npz','train_data.npz')\n",
    "test_data_fname = os.path.join(original_data_path, 'split_npz','test_data.npz')\n",
    "val_data_fname = os.path.join(original_data_path, 'split_npz','validation_data.npz')\n",
    "\n",
    "# loading\n",
    "train_data = np.load(train_data_fname)\n",
    "test_data = np.load(test_data_fname)\n",
    "val_data = np.load(val_data_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  (14000, 4096) and labels:  (14000,)\n",
      "Size of validation data:  (4000, 4096) and labels:  (4000,)\n",
      "Size of testing data:  (2000, 4096) and labels:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "images_train = train_data['images_train']\n",
    "labels_train = train_data['labels_train']\n",
    "images_test = test_data['images_test']\n",
    "labels_test = test_data['labels_test']\n",
    "images_val = val_data['images_val']\n",
    "labels_val = val_data['labels_val']\n",
    "\n",
    "print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "print(\"Size of validation data: \", np.shape(images_val), \"and labels: \", np.shape(labels_val))\n",
    "print(\"Size of testing data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  (14000, 64, 64, 1)\n",
      "Size of validation data:  (4000, 64, 64, 1)\n",
      "Size of testing data:  (2000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "#print(K.image_data_format())\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "    images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "    images_val = images_val.reshape(images_val.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    images_train = images_train.reshape(images_train.shape[0], img_rows, img_cols, 1)\n",
    "    images_test = images_test.reshape(images_test.shape[0], img_rows, img_cols, 1)\n",
    "    images_val = images_val.reshape(images_val.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "print(\"Size of training data: \", np.shape(images_train))\n",
    "print(\"Size of validation data: \", np.shape(images_val))\n",
    "print(\"Size of testing data: \", np.shape(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 12 random train images\n",
    "shi.plot_12images(images_train, labels_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "labels_train shape: (14000, 2)\n",
      "labels_test shape: (2000, 2)\n",
      "labels_val shape: (4000, 2)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train, num_classes=2)\n",
    "labels_test = np_utils.to_categorical(labels_test, num_classes=2)\n",
    "labels_val = np_utils.to_categorical(labels_val, num_classes=2)\n",
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_test shape:', labels_test.shape)\n",
    "print('labels_val shape:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the training\n",
    "batch_size = 200\n",
    "epochs = 5\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 256)               29491456  \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 29,566,466\n",
      "Trainable params: 29,566,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "model = mod.generate_model(input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 4000 samples\n",
      "Epoch 1/5\n",
      "14000/14000 [==============================] - 375s 27ms/step - loss: 0.6864 - acc: 0.5933 - val_loss: 0.5620 - val_acc: 0.7013\n",
      "Epoch 2/5\n",
      "14000/14000 [==============================] - 440s 31ms/step - loss: 0.4450 - acc: 0.7868 - val_loss: 0.2603 - val_acc: 0.8937\n",
      "Epoch 3/5\n",
      "14000/14000 [==============================] - 412s 29ms/step - loss: 0.2600 - acc: 0.9025 - val_loss: 0.1049 - val_acc: 0.9685\n",
      "Epoch 4/5\n",
      "14000/14000 [==============================] - 411s 29ms/step - loss: 0.1126 - acc: 0.9588 - val_loss: 0.0878 - val_acc: 0.9632\n",
      "Epoch 5/5\n",
      "14000/14000 [==============================] - 408s 29ms/step - loss: 0.0776 - acc: 0.9724 - val_loss: 0.1317 - val_acc: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f9c6d09c320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train \n",
    "mod.train_model(model, images_train, labels_train, images_val, labels_val, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename for model saving\n",
    "model_fname = os.path.join(original_data_path, 'Model','model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(model_fname)\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
