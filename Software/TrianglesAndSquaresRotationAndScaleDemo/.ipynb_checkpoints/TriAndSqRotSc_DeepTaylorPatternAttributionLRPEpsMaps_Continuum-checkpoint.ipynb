{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability maps continuum? \n",
    "## XAI methods: DeepTaylor, PatternAttribution and LRP Epsilon \n",
    "### on the Triangles and Squares (Rotaion & Scaling) dataset using iNNvestigate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils_mnist.py\")\n",
    "eutils = imp.load_source(\"utils\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils.py\")\n",
    "\n",
    "from code import shape_images as shi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "# data paths\n",
    "original_data_path = \"/home/elena/eStep/XAI/Data/TrianglesAndSquaresRotationScale\"\n",
    "\n",
    "test_data_fname = os.path.join(original_data_path, 'split_npz','test_data.npz')\n",
    "\n",
    "# loading\n",
    "test_data = np.load(test_data_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of testing data:  (2000, 4096) and labels:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "images_test = test_data['images_test']\n",
    "labels_test = test_data['labels_test']\n",
    "\n",
    "print(\"Size of testing data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of testing data:  (2000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    images_test = images_test.reshape(images_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "print(\"Size of testing data: \", np.shape(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 12 random test images\n",
    "shi.plot_12images(images_test, labels_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_test_formatted shape: (2000, 2)\n",
      "labels_test:  [0. 1. 0. ... 1. 1. 0.]\n",
      "labels_test_formated:  [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_test_formatted = np_utils.to_categorical(labels_test, num_classes=2)\n",
    "\n",
    "print('labels_test_formatted shape:', labels_test_formatted.shape)\n",
    "print('labels_test: ', labels_test)\n",
    "print('labels_test_formated: ', labels_test_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 256)               29491456  \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 29,566,466\n",
      "Trainable params: 29,566,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# filename for model \n",
    "model_fname = os.path.join(original_data_path, 'Models','model.h5')\n",
    "\n",
    "# load the trained model\n",
    "model = load_model(model_fname) \n",
    "print(\"Loaded model from disk: \")\n",
    "\n",
    "# print summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.10065763419866562\n",
      "Test accuracy: 97.65 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(images_test, labels_test_formatted, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick up 10 random images and classify them using the trained model\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "figsize = (8, 6)\n",
    "plt.figure(figsize=figsize)\n",
    "j=0\n",
    "nim = len(labels_test)\n",
    "\n",
    "for _ in range(10):\n",
    "    ind=int(np.random.randint(1,nim))\n",
    "    img=images_test[ind,:]\n",
    "    img=np.reshape(img,(64,64))\n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    label=labels_test[ind]\n",
    "       \n",
    "    predictions = model.predict(X);\n",
    "    pred = np.argmax(predictions) \n",
    "    \n",
    "    j = j+1\n",
    "    plt.subplot(2, 5, j)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('n=%d n̂=%d' % (label, pred))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the indicies of the missclassified images and display some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2dbff3950b00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#indices_wrong = [i for i,v in enumerate(predictions) if np.argmax(predictions[i])!=np.argmax(labels_test_formatted[i])]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindices_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missclassified images: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_wrong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages_test_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_wrong\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = model.predict(images_test)\n",
    "#indices_wrong = [i for i,v in enumerate(predictions) if np.argmax(predictions[i])!=np.argmax(labels_test_formatted[i])]\n",
    "indices_wrong = [i for i,v in enumerate(predictions) if np.argmax(predictions[i])!=labels_test[i]]\n",
    "print('Missclassified images: ', len(indices_wrong)/len(labels_test)*100, '%')\n",
    "images_test_wrong = images_test[indices_wrong]\n",
    "labels_test_wrong = labels_test[indices_wrong]\n",
    "print('Number of missclassified images: ', len(indices_wrong))\n",
    "predictions_wrong = predictions[indices_wrong]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 10 missclassified images \n",
    "figsize = (8, 6)\n",
    "plt.figure(figsize=figsize)\n",
    "for ind in range(10):\n",
    "\n",
    "    img = images_test_wrong[ind].reshape(img_rows, img_cols)\n",
    "    lab = labels_test_wrong[ind]\n",
    "    pred = np.argmax(predictions_wrong[ind])\n",
    "    \n",
    "    plt.subplot(2, 5, ind+1)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) \n",
    "    plt.title('n=%d n̂=%d' % (lab, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the indicies of the correctly classified images and display some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = [i for i,v in enumerate(predictions) if np.argmax(predictions[i])==(labels_test[i])]\n",
    "print('Correctly classified images: ', len(indices_correct)/len(labels_test)*100, '%')\n",
    "images_test_correct = images_test[indices_correct]\n",
    "labels_test_correct = labels_test[indices_correct]\n",
    "print('Number of correctly classified images: ', len(indices_correct))\n",
    "predictions_correct = predictions[indices_correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 10 correctly classified images \n",
    "figsize = (8, 6)\n",
    "plt.figure(figsize=figsize)\n",
    "for ind in range(10):\n",
    "      \n",
    "    img = images_test_correct[ind].reshape(img_rows, img_cols)\n",
    "    lab = labels_test_correct[ind]\n",
    "    pred = np.argmax(predictions_correct[ind])\n",
    "    \n",
    "    plt.subplot(2, 5, ind+1)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) \n",
    "    plt.title('n=%d n̂=%d' % (lab, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create subsets of images of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the correctly classified and missclassified images into squares and triangles and sort them on contrast and size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the correct images in squares and triangles\n",
    "\n",
    "# squares\n",
    "label = 0\n",
    "\n",
    "squares_correct = shi.select_shape(images_test_correct, labels_test_correct, label)\n",
    "print('There are ',np.shape(squares_correct)[0] , ' square shapes in the test set wich have been classified correctly.')\n",
    "\n",
    "shi.plot_12images(squares_correct)\n",
    "\n",
    "# triangles\n",
    "label = 1\n",
    "\n",
    "triangles_correct = shi.select_shape(images_test_correct, labels_test_correct, label)\n",
    "print('There are ',np.shape(triangles_correct)[0] , ' triangle shapes in the test set wich have been classified correctly.')\n",
    "\n",
    "shi.plot_12images(triangles_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the missclassified images in squares and triangles\n",
    "\n",
    "# squares\n",
    "label = 0\n",
    "\n",
    "squares_wrong = shi.select_shape(images_test_wrong, labels_test_wrong, label)\n",
    "print('There are ',np.shape(squares_wrong)[0] , ' square shapes in the test set wich have been missclassified.')\n",
    "\n",
    "# display the first 6 missclassified images \n",
    "figsize = (8, 6)\n",
    "plt.figure(figsize=figsize)\n",
    "for ind in range(41):\n",
    "      \n",
    "    img = squares_wrong[ind].reshape(img_rows, img_cols)\n",
    "    \n",
    "    plt.subplot(7, 8, ind+1)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "# triangles\n",
    "label = 1\n",
    "\n",
    "triangles_wrong = shi.select_shape(images_test_wrong, labels_test_wrong, label)\n",
    "print('There are ',np.shape(triangles_wrong)[0] , ' triangle shapes in the test set wich have been missclassified.')\n",
    "\n",
    "# display the  missclassified images \n",
    "figsize = (8, 6)\n",
    "plt.figure(figsize=figsize)\n",
    "for ind in range(6):\n",
    "      \n",
    "    img = triangles_wrong[ind].reshape(img_rows, img_cols)\n",
    "    \n",
    "    plt.subplot(7, 8, ind+1)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of top analysis methods by preparing tuples containing the methods' string identifiers used by innvestigate.analyzer.create_analyzer(...), some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_range = [0, 1]\n",
    "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(images_test, input_range)\n",
    "def input_postprocessing(X):\n",
    "    #return revert_preprocessing(X) / 255\n",
    "    #return 1-X\n",
    "    return X\n",
    "\n",
    "\n",
    "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
    "ri = input_range[0]  # reference input\n",
    "\n",
    "# Configure analysis methods and properties\n",
    "methods = [\n",
    "    # NAME            OPT.PARAMS                POSTPROC FXN               TITLE\n",
    "\n",
    "    # Show input\n",
    "    (\"input\",         {},                       input_postprocessing,      \"Input\"),\n",
    "\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",  {\"pattern_type\": \"relu\"}, mnistutils.heatmap,        \"PatternAttribution\"),\n",
    "       \n",
    "    (\"deep_taylor.bounded\",   {\"low\": input_range[0],\"high\": input_range[1]}, mnistutils.heatmap,        \"DeepTaylor\"),\n",
    "    \n",
    "    (\"lrp.epsilon\",           {\"epsilon\": 1},           mnistutils.heatmap,        \"LRP-Epsilon\"),\n",
    "\n",
    "]\n",
    "    \n",
    "print('Considered number of explainability methods:', len(methods)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop instantiates the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model without trailing softmax\n",
    "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "path_to_analyzers = \"/home/elena/eStep/XAI/Data/TrianglesAndSquaresRotationScale/Analyzers/\"  \n",
    "\n",
    "\n",
    "# Create analyzers.\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    fname = os.path.join(path_to_analyzers, method[0]+'.npz')\n",
    "    \n",
    "    analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
    "                                            model_wo_softmax, # model without softmax output\n",
    "                                            neuron_selection_mode=\"index\",\n",
    "                                            **method[1])     \n",
    "    \n",
    "    if os.path.isfile(fname) :\n",
    "        print(\"Analyzer\", method[0], \"exists! Loading...\")\n",
    "        analyzer = analyzer.load_npz(fname)\n",
    "\n",
    "    \n",
    "    analyzers.append(analyzer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis code\n",
    "def analysis():\n",
    "    for image_nr, (x, y) in enumerate(test_images):\n",
    "        y = int(y)\n",
    "        # Add batch axis.\n",
    "        x = x[None, :, :, :]\n",
    "\n",
    "        analysis = np.zeros([num_classes, len(analyzers), 64, 64, 3])\n",
    "        text = []\n",
    "\n",
    "        for ii, output_neuron in enumerate([0, 1]):\n",
    "            # Predict final activations, probabilites, and label.\n",
    "            presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "            prob = model.predict_on_batch(x)[0]\n",
    "            y_hat = prob.argmax()\n",
    "\n",
    "            # Save prediction info:\n",
    "            text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                         \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                         \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                         \"%s\" % label_to_class_name[output_neuron]\n",
    "                        ))\n",
    "\n",
    "\n",
    "            for aidx, analyzer in enumerate(analyzers):\n",
    "                # Analyze.\n",
    "                a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "                # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "                a = mnistutils.postprocess(a)\n",
    "                # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "                a = methods[aidx][2](a)\n",
    "                # Store the analysis.\n",
    "                analysis[ii, aidx] = a[0]\n",
    "\n",
    "        print(\"-\"*80)\n",
    "        print(\"Image nr. {}; prediction: {} \".format(image_nr, y_hat))\n",
    "        # Prepare the grid as rectengular list\n",
    "        grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "                for i in range(analysis.shape[0])]\n",
    "        # Prepare the labels\n",
    "        label, presm, prob, pred = zip(*text)\n",
    "        print(label)\n",
    "        row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "       # row_labels_right = []\n",
    "        row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "        col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "        # Plot the analysis.\n",
    "        file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "       # print(file_name)\n",
    "        if file_name is not None:\n",
    "            file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]   \n",
    "        n_rows = len(grid)\n",
    "        n_cols = len(grid[0])\n",
    "        figsize = (2*n_cols, 2*(n_rows+1))\n",
    "        eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, figsize=figsize, file_name=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze correctly classified squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the corectly classified squares on contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sorting function\n",
    "contr_sorted_squares_correct, _, _ = shi.sort_contrast(squares_correct)\n",
    "# plot 12 images after sorting\n",
    "shi.plot_12seqimages(contr_sorted_squares_correct)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(contr_sorted_squares_correct,None, 250)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(contr_sorted_squares_correct,None, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = np.shape(squares_correct)[0]\n",
    "ntim = 5\n",
    "indices1 = range(0,ntim)\n",
    "indices2 = range(250,250+ntim)\n",
    "indices3 = range(500,500+ntim)\n",
    "indices4 = range(750,750+ntim)\n",
    "indices5 = range(900,900+ntim)\n",
    "\n",
    "indices = np.concatenate([indices1, indices2, indices3, indices4, indices5])\n",
    "num_classes = 2\n",
    "labels = np.zeros(nim)\n",
    "\n",
    "test_images = list(zip(contr_sorted_squares_correct[indices], labels))\n",
    "\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the corectly classified squares on size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sorting function\n",
    "size_sorted_squares_correct, _, _ = shi.sort_size(squares_correct)\n",
    "# plot 12 images after sorting\n",
    "shi.plot_12seqimages(size_sorted_squares_correct)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(size_sorted_squares_correct,None, 250)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(size_sorted_squares_correct,None, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = np.shape(squares_correct)[0]\n",
    "ntim = 5\n",
    "indices1 = range(0,ntim)\n",
    "indices2 = range(250,250+ntim)\n",
    "indices3 = range(500,500+ntim)\n",
    "indices4 = range(750,750+ntim)\n",
    "indices5 = range(900,900+ntim)\n",
    "\n",
    "indices = np.concatenate([indices1, indices2, indices3, indices4, indices5])\n",
    "num_classes = 2\n",
    "labels = np.zeros(nim)\n",
    "\n",
    "test_images = list(zip(size_sorted_squares_correct[indices], labels))\n",
    "\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze correctly classified triangles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the corectly classified triangles on contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sorting function\n",
    "contr_sorted_triangles_correct, _, _ = shi.sort_contrast(triangles_correct)\n",
    "# plot 12 images after sorting\n",
    "shi.plot_12seqimages(contr_sorted_triangles_correct)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(contr_sorted_triangles_correct,None, 250)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(contr_sorted_triangles_correct,None, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = np.shape(triangles_correct)[0]\n",
    "ntim = 5\n",
    "indices1 = range(0,ntim)\n",
    "indices2 = range(250,250+ntim)\n",
    "indices3 = range(500,500+ntim)\n",
    "indices4 = range(750,750+ntim)\n",
    "indices5 = range(900,900+ntim)\n",
    "\n",
    "indices = np.concatenate([indices1, indices2, indices3, indices4, indices5])\n",
    "num_classes = 2\n",
    "labels = np.ones(nim)\n",
    "\n",
    "test_images = list(zip(contr_sorted_triangles_correct[indices], labels))\n",
    "\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the corectly classified triangles on size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sorting function\n",
    "size_sorted_triangles_correct, _, _ = shi.sort_size(triangles_correct)\n",
    "# plot 12 images after sorting\n",
    "shi.plot_12seqimages(size_sorted_triangles_correct)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(size_sorted_triangles_correct,None, 250)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(size_sorted_triangles_correct,None, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = np.shape(triangles_correct)[0]\n",
    "ntim = 5\n",
    "indices1 = range(0,ntim)\n",
    "indices2 = range(250,250+ntim)\n",
    "indices3 = range(500,500+ntim)\n",
    "indices4 = range(750,750+ntim)\n",
    "indices5 = range(900,900+ntim)\n",
    "\n",
    "indices = np.concatenate([indices1, indices2, indices3, indices4, indices5])\n",
    "num_classes = 2\n",
    "labels = np.ones(nim)\n",
    "\n",
    "test_images = list(zip(size_sorted_triangles_correct[indices], labels))\n",
    "\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze missclassified squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the wrongly classified squares on contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sorting function\n",
    "contr_sorted_squares_wrong, _, _ = shi.sort_contrast(squares_wrong)\n",
    "# plot 12 images after sorting\n",
    "shi.plot_12seqimages(contr_sorted_squares_wrong)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(contr_sorted_squares_wrong,None, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = np.shape(squares_wrong)[0]\n",
    "\n",
    "indices = range(0,nim)\n",
    "\n",
    "num_classes = 2\n",
    "labels = np.zeros(nim) # triangles missclssifed as squares\n",
    "\n",
    "test_images = list(zip(contr_sorted_squares_wrong[indices], labels))\n",
    "\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the wrongly classified squares on size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sorting function\n",
    "size_sorted_squares_wrong, _, _ = shi.sort_size(squares_wrong)\n",
    "# plot 12 images after sorting\n",
    "shi.plot_12seqimages(size_sorted_squares_wrong)\n",
    "print('---------------------------------------------')\n",
    "shi.plot_12seqimages(size_sorted_squares_wrong,None, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = np.shape(squares_wrong)[0]\n",
    "\n",
    "indices = range(0,nim)\n",
    "\n",
    "num_classes = 2\n",
    "labels = np.zeros(nim) # triangles missclssifed as squares\n",
    "\n",
    "test_images = list(zip(size_sorted_squares_wrong[indices], labels))\n",
    "\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze missclassified triangles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the wrongly classified triangles on contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sorting function\n",
    "contr_sorted_triangles_wrong, _, _ = shi.sort_contrast(triangles_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = np.shape(triangles_wrong)[0]\n",
    "\n",
    "indices = range(0,nim)\n",
    "\n",
    "num_classes = 2\n",
    "labels = np.ones(nim) # squares missclssifed as triangles\n",
    "\n",
    "test_images = list(zip(contr_sorted_triangles_wrong[indices], labels))\n",
    "\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the wrongly classified triangles on size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sorting function\n",
    "size_sorted_triangles_wrong, _, _ = shi.sort_size(triangles_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = np.shape(triangles_wrong)[0]\n",
    "\n",
    "indices = range(0,nim)\n",
    "\n",
    "num_classes = 2\n",
    "labels = np.ones(nim) # squares missclssifed as triangles\n",
    "\n",
    "test_images = list(zip(size_sorted_triangles_wrong[indices], labels))\n",
    "\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
