{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Explainability Demo\n",
    "\n",
    "*At the moment this is work in progress and in the experimental phase. If the experiment is successsful, e.g. we get meaningful heatmaps for the task, this will turn into a real demo!*\n",
    "\n",
    "**The purpose of this demo is to show the ability of DNN explainability method(s) to generate meanfingful heatmaps for the relevance of the input image pixels to the output resut of a CNN model. The task is chosen to be lassification of 2 simple shapes - triangle and square rather than a classical object classificaiton task to minimize human interpretation of the resulting heatmaps.**\n",
    "\n",
    "The explainability tool [iNNvestigate](https://github.com/albermax/innvestigate) is chosen as it offers open source implementatons of several explainability methods. Since it supports [Keras](https://keras.io/), the framework (with [Tensorflow](https://www.tensorflow.org/) as backend) is used to genrate the CNN model(s), though our vision is to go for at least [PyTorch](https://pytorch.org/) deep learning library and the related [Captum](https://captum.ai/) explainability library and definitely towards using DNN model standards such as [ONNX](https://onnx.ai/). This [list of explainability tools](https://github.com/NLeSC/XAI/blob/master/State-of-the-art/AI_Explainability_OSTools.docx) sumamrizes the availability of explainability tools.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "The original dataset has been generated in MATLAB and stored at [SURF drive](https://surfdrive.surf.nl/files/index.php/s/MoCVal7gxS4aX51?path=%2Fdata%2FTrianglesAndSquaresRotationScale). There are 20 000 (20k) gray scale images of size 64 x 64 with either (rotated and scaled) triangle or square shapes. The shape and background are of random uniform gray scale level.\n",
    "\n",
    "The notebook [DataPreparation](https://github.com/NLeSC/XAI/blob/master/Software/TrianglesAndSquaresRotationAndScaleDemo/DataPreparation.ipynb) is used to load the original data, split the dataset into training (14k), testing (2k) and validation (4k) and save the files as numpy compressed (NPZ). The resulting files are also stored in a subfolder on [SURF drive](https://surfdrive.surf.nl/files/index.php/s/MoCVal7gxS4aX51?path=%2Fdata%2FTrianglesAndSquaresRotationScale%2Fsplit_npz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "The generated data per dataset have been split in 14k images for training, 4k for validaiton and 2k for testing. \n",
    "Notebook for the [model training](https://github.com/NLeSC/XAI/blob/master/Software/TrianglesAndSquaresRotationAndScaleDemo/TrainAndTestClassificationModel.ipynb)\n",
    "\n",
    "The obtained accuracies are as follows: 95.88% on he train set and 97.38% on the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "\n",
    "The notebook for the [model testing](https://github.com/NLeSC/XAI/blob/master/Software/TrianglesAndSquaresRotationAndScaleDemo/TrainAndTestClassificationModel.ipynb)\n",
    "\n",
    "The obtained test accuracy: 97.65%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability heatmaps\n",
    "\n",
    "The links to the notebooks for generating explainability heatmaps:\n",
    "\n",
    "[4 explainability  methods heatmaps](https://github.com/NLeSC/XAI/blob/master/Software/TrianglesAndSquaresRotationAndScaleDemo/TriAndSqRotSc_ManyImagesSomeMethods.ipynb)\n",
    "\n",
    "[PatternNet and PaternAttribution heatmaps](https://github.com/NLeSC/XAI/blob/master/Software/TrianglesAndSquaresRotationAndScaleDemo/TriAndSqRotSc_ManyImagesSomeMethods-PatternNetAndAttribution.ipynb)\n",
    "\n",
    "-----------------------\n",
    "Experiments\n",
    "\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
