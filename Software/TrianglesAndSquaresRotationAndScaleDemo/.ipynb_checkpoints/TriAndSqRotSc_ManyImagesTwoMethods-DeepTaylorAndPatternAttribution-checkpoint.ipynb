{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two analysers - DeepTaylor and PatternAttribution of the classification model on many images of the  on Triangles and Squares (Rotaion & Scaling) dataset using iNNvestigate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils_mnist.py\")\n",
    "eutils = imp.load_source(\"utils\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils.py\")\n",
    "\n",
    "from code import shape_images as shi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "# data paths\n",
    "original_data_path = \"/home/elena/eStep/XAI/Data/TrianglesAndSquaresRotationScale\"\n",
    "\n",
    "train_data_fname = os.path.join(original_data_path, 'split_npz','train_data.npz')\n",
    "test_data_fname = os.path.join(original_data_path, 'split_npz','test_data.npz')\n",
    "\n",
    "# loading\n",
    "train_data = np.load(train_data_fname)\n",
    "test_data = np.load(test_data_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  (14000, 4096) and labels:  (14000,)\n",
      "Size of testing data:  (2000, 4096) and labels:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "images_train = train_data['images_train']\n",
    "labels_train = train_data['labels_train']\n",
    "images_test = test_data['images_test']\n",
    "labels_test_or = test_data['labels_test']\n",
    "\n",
    "print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "print(\"Size of testing data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test_or))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  (14000, 64, 64, 1)\n",
      "Size of testing data:  (2000, 4096)\n"
     ]
    }
   ],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "    images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    images_train = images_train.reshape(images_train.shape[0], img_rows, img_cols, 1)\n",
    "    images_test = images_test.reshape(images_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "print(\"Size of training data: \", np.shape(images_train))\n",
    "print(\"Size of testing data: \", np.shape(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdIAAAFoCAYAAADjMXolAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFiVJREFUeJzt3c+rXVcVB/C1Y4ktpmkQE2gNFjGgwWKdSGdBcCKCDoyYYBvwH8jMqZKJEx1U6qQzUTNIUHQgDhwJ0qEDLS2J8BQrImIUDcZWhbgd9F29eXk/7r37nHv23ufzgQfJ7XsnOyzS71vrrHteyjkHALCZY1MfAABaJkgBoIAgBYACghQACghSACggSAGggCAFgAKzD9KU0idSSrdTSm+mlH6aUnp66jOxuZTS8ZTS91NKv00p5ZTSx6c+E5tTz/70WNNZB2lK6T0R8YOI+HJEvDsifh4RNyc9FEN4JSJeiIg/Tn0QBqGe/emqpk0H6e53NF9KKb2aUrqbUrqZUnp0jUt8NiJezzl/L+f8z4i4FhHPppQ+NMqBOVJpTXPO/845fyPn/EpE3B/xqKxAPfujpg9rOkh3fT4iPhkR74+Ij0TEF1NK70sp/e2Qjy/sfu2HI+KXiwvlnP8REb/efZ3plNSU+qhnf9R0ySNTH2AAL+Wc/xARkVL6UUR8NOf8ckScWuFrT0TEnT2v3Y2Ix4c9ImsqqSn1Uc/+qOmSHjrS5Rn7m/F2OK7qXkSc3PPayYj4e+mhKFJSU+qjnv1R0yU9BOlDdkcM9w75eH73U1+PiGeXvu5dEfGB3depyBo1pQHq2Z8517SH0e5Dcs6/i9W+Q/phRHw9pXQxIn4cEV+JiFdzzrfHPB/rW6OmkVJ6Z0Sk3d8e312E+Ff2MwOroZ79mXNNu+xIV5VzvhMRFyPiqxHx14h4LiIuT3oohvCriHgrIt4bET/Z/bX3B7dLPfvTVU1To98AAEAVZt2RAkApQQoABQQpABQQpABQQJACQIG13kf62GOP5ccf9/S8qdy5c+fPOefTQ13v1KlT+amnnhrqcqzp1q1bg9YzIuKJJ57IZ86cGfKSrGFnZ2fQmj7yyCP5+PHjQ12ONb311lsr1XOtIH388cfj4sWLm5+KIi+//PIbQ17vqaeeiu985ztDXpI1fOxjHxu0nhERZ86ciZdeemnoy7KiT33qU4PW9Pjx4/HBD35wyEuyhl/84hcr1dNoFwAKCFIAKCBIAaCAIAWAAoIUAAoIUmByV69ejatXr059DNiIIAWAAoIUmNRyJ6orpUVrPZBh21577bWHXnvmmWcmOAkA7E9HCgAFqu5I97O3S9WhQpsOGuMuXv/mN7+5zePAxqoN0v3Guqt+nnAFYFuMdgGgQJdB+tprrz3wAdRlle1cG7y0otrR7pCMf6FN7pfSgi47UgDYluo60m2NYm3/wvYZ19bl2rVr+/6a9VQXpFNZDlah2rbr16//79cvvPDChCdhWUmIXr161Xh3ZHuDVLCuzmgXAAroSPdhOalNy50oUMbYd3VVBWnNb1VxT7VuQrReQ90XtcE7nf2CVLj+n9EuABSoqiNtifFvHXSiMA2j3/8TpAMy/t2uVUL0+vXrNncnNMbbXWzw1mfuG79GuwBQoIqOtOYloxLGv+MwzsXiUd3mNvatIkjnxIMfygjRNniCURuuXbs2etDNYePXaBcACuhIqZ4ulINYPGpTb8tJkwdpr/dHKTdUgC6uY3t3O4x1WVfr91SNdgGgwOQd6RxZMjqacW57pupEbfD2pcXlJEFKVQQosFfto1+jXQAoMFlHasmIvXSj7aphwcgG7zzUuPFrtLtl7o8+bFsB6rm7/XO/dH5qGPsa7QJAgUk6UmNdFoxz21bDSJcyiy6uhhFpqak2fo12mYQAZUzul7KwjdGv0S4AFNCRboklI11ob4x1acXY492tBql7o/NVS4h67m65VgLUBi8R27lHarQLAAWMdhlVLZ0oMC/b3ELWkW7BXO+PCtH+tDLWXdbimSmz7bfyCFIAKLC10a5Fo/nQiVIbi0f9m/KBEu6RMigh2ifjUWpVwxOZjHYBoIAgHdEzzzwzm0Wj69evN9WNtnRWhqOzPlgNnd26ajnz6KNd90b7J5T6JnyoTS0BuqAjBYAClo0otvdxezpUamaDt021daHLBOlI5nJvdD/7PcdWuLbHSJda1ByiEUa7AFBk1I7UohELNY5//SSYg82hG/XDv+tXeye6YLQ7sDmPdNdh/EsN3C+tVyshGmG0CwBFdKRUo8bx79zMYaRLvVrqQpeNEqTujTIE41+2xf3Sty2CbNuB1mqALhjtAkABo90BWTQa3xjj3+vXr9vcDWNdptF6NxohSGmc8S9DscG7XT0E6ILRLgAUGKUjXR5xWjxi22z/Qp166kKXjT7a3e++YW/h6t5o3Yx/V2OkyZh6DdEIo10AKDLJstHeDq63DpX62dKF7ei5E12oYmt3DuNfgLmZQ4hGGO0CQJEqOtL9tDL+tWgE9ObatWsbd5Nz6UKXVRukexn/AtRrjgG6YLQLAAWa6Uj348EPANObczca0XiQLtv2PVX3RoG5m3uALhjtAkCBbjrSvSwnAQxPF/qwboN0P628pQagRkJ0f0a7AFBgVh3pXpuOfy0aAXOiEz3crIN0P8a/AMJzHUa7AFBAR3oEY1wADqMjBYACghQACghSACggSAGggCAFgAKCFAAKCFIAKCBIAaCAIAWAAoIUAAoIUgAokHLOq39ySnci4o3xjsMRns45nx7qYuo5uUHrGaGmFfBvtC8r1XOtIAUAHmS0CwAFBCkAFJh9kKaUPpFSup1SejOl9NOU0tNTn4kyatqPlNLxlNL3U0q/TSnllNLHpz4TZXqs6ayDNKX0noj4QUR8OSLeHRE/j4ibkx6KImrapVci4oWI+OPUB2EwXdW06SDd/Y7mSymlV1NKd1NKN1NKj65xic9GxOs55+/lnP8ZEdci4tmU0odGOTBHUtO+lNYz5/zvnPM3cs6vRMT9EY/KitT0YU0H6a7PR8QnI+L9EfGRiPhiSul9KaW/HfLxhd2v/XBE/HJxoZzzPyLi17uvMx017UtJPamTmi55ZOoDDOClnPMfIiJSSj+KiI/mnF+OiFMrfO2JiLiz57W7EfH4sEdkTWral5J6Uic1XdJDR7o8Y38z3v4f6aruRcTJPa+djIi/lx6KImral5J6Uic1XdJDkD5kd8Rw75CP53c/9fWIeHbp694VER/YfZ2KqGlf1qgnjZhzTXsY7T4k5/y7WO07pB9GxNdTShcj4scR8ZWIeDXnfHvM87E+Ne3LGvWMlNI7IyLt/vb47mLLv7LHslVlzjXtsiNdVc75TkRcjIivRsRfI+K5iLg86aEooqZd+lVEvBUR742In+z+2nuD29ZVTT1rFwAKzLojBYBSghQACghSACggSAGggCAFgAJrvY/0iSeeyGfOnBnrLBxhZ2fnzznn00Nd77HHHssnT+59CBDb8qc//WnQekZEpJSs4U9r0Jqq5+RWqudaQXrmzJl48cUXNz8SRT796U+/MeT1Tp48Gc8/3+3DRqr34osvDlrPhWPHDJqm8p///Gfwmr7jHe8Y+pKs6P79+yvV0784ACggSAGggCAFgAKCFAAKCFIAKCBIAaCAIAWAAoIUAAoIUgAoIEgBoIAgBYACghQACghSACiw1k9/6dmNGzceeu3y5csTnASAlsw6SPcLTwBYh9EuABSYXUe6Thd648YN410ADjWLIDXCBWAsRrsAUKDbjnSoLnRxHSNeAPbTVZAa4bbvxIkTD7127969CU5CDa5cuRIREd/97ncnPkm9fv/732/tzzp79uzW/qyWGO0CQIGmO9JtdqA2eKez3KXqTudj0Y1SD93v/poLUuPbfu031j3sc4RqnwToes6ePbvVgNuWbfydhgpro10AKNBER1pLF2qDty660/4c1I1euXLFwhHVqjZIawlPxrfKSHedawjV9hjnllmMKHsc8Y5lyHuwRrsAUKCqjrSVLtQGb910p23RjdK6yYO0lfBkHEOMdVe9vlCty7oB6uEMR+t1g3dIY7ytxmgXAApM0pH20IXa4G2P7rQexrlMYayHPGwtSHsIT4Yz9kh3nT9fqG6PAB2fDd7tM9oFgAKCtJBOu30nTpz43wfjGaob1dWyrrNnz4767N7Jt3aZn5oDy8h3eIJvGjZ437aNh9/rSAGgwNaC1HYrzI9ulDkw2h2At8KspuaRLsMaO0A9nGE1c97g3ebPMzXaBYACW+1IFx2bTVdqZsmojHEuU9tmNxqhIx2UbxAOZqzbvytXrgjRSm07WOZGkAJAgUmC1FIOtTLW3YxOlBqM/eCFg9jaHZgN3gcZ6fZt6gC9cuWKzd0V9b7BO+X42mgXAApM1pHa4KUmRrrrm7obhVoY7Y7kxo0bsx/vGuv2SYC2rbdn8NawkWy0CwAFJg/SuXdtTM9Yd3U1dqPevzpfNXSjEUa7o5rrBq+Rbn8EVV963+Ddtsk7UgBoWRUdqQ1epmCkC22qZaS7UEWQ9s4GL6076KEHNY18PZxhfS1u8NYWohFGuwBQREfK4JZHprUuHhnrDqOFThXGVlWQXr582X3SzrQQqgxPwLajlQ3eGke6C0a7AFCgqo60NxaMHlRDd2qkO62jloFKO9bF11s66kvN3WhEhUHa+lthhOdqaghV6mMkPJ0WN3hrYbQLAAWq60hbpAsts63u1Fi3XTrVeap9pLtQbZDWvsErPMdh5Ms63AsdVk0bvK2EaITRLgAUqbYjrZEudLuG6k6NdIExVR2kNWzwCs86GPnC9ky5wdvSSHfBaBcAClTdkU5FF1q3dbpTY11oR4vdaEQjQTr2Bq/gbJeRL4yjpg3e2hntAkCBJjrSMehC+2OMC21qdaS70EyQDrHBKzwB1jP2Bm/rIRphtAsARZrpSDelCwVgTM0F6SobvMITYDhjbPD2MNJdMNoFgALNdaQH0YUCtKGnbjSi0SAVmgDbN+UzeGtmtAsABZrsSAFoT28j3QUdKQArO3v27EaB2GuIRghSACgiSAGggCAFYG2rjmo3HQW3RJACQAFBCsAoeu9EFwQpABuZw9h2FYIUAAp4IAMAg5pbl6ojBaDIcnDOLUQjBCkAFDHaBaDYHDvRBR0pABQQpABQIOWcV//klO5ExBvjHYcjPJ1zPj3UxdRzcoPWM0JNK+DfaF9WqudaQQoAPMhoFwAKCFIAKDDrIE0pHU8pfT+l9NuUUk4pfXzqM1EupfSJlNLtlNKbKaWfppSenvpMbE49+9NbTWcdpLteiYgXIuKPUx+Eciml90TEDyLiyxHx7oj4eUTcnPRQbEw9+9NjTZsO0t1O8ksppVdTSndTSjdTSo+u+vU553/nnL+Rc34lIu6PeFRWVFrTiPhsRLyec/5ezvmfEXEtIp5NKX1olANzKPXsj5o+rOkg3fX5iPhkRLw/Ij4SEV9MKb0vpfS3Qz6+MO2ROUJJTT8cEb9cXCjn/I+I+PXu60xDPfujpkt6eETgSznnP0REpJR+FBEfzTm/HBGnpj0WBUpqeiIi7ux57W5EPD7sEVmDevZHTZf00JEu39t8M94uEm0rqem9iDi557WTEfH30kOxMfXsj5ou6SFIH7I7Yrh3yMfzU5+R9axR09cj4tmlr3tXRHxg93UqoZ79mXNNexjtPiTn/LtY8TuklNI7IyLt/vb47k3zf2WPfKrKGjX9YUR8PaV0MSJ+HBFfiYhXc863xzwf61HP/sy5pl12pGv6VUS8FRHvjYif7P666fc0zVnO+U5EXIyIr0bEXyPiuYi4POmh2Jh69qfHmnrWLgAU0JECQAFBCgAFBCkAFBCkAFBAkAJAgbXeR/roo4/mEyc8OGgqf/nLX/6ccz491PVOnjyZT58e7HKs6Te/+c2g9YyIOHbsWD52zPfHU7l///6gNT116lR+8sknh7oca7p9+/ZK9VwrSE+cOBGf+cxnNj8VRb71rW+9MeT1Tp8+HV/72teGvCRr+NznPjdoPSMijh07Fr7Znc7du3cHremTTz4Z3/72t4e8JGt47rnnVqqnb10BoIAgBYACghQACghSACggSAGgwCyC9NKlS3Hp0qWpjwFAh2YRpAAwli5/sPey5U700qVLcfPmzQlPA4zp3Llzh/73nZ2dLZ2EOek+SIH+HBWYsE1GuwBQoNuO9KDlosXrRrxQP50nLeg2SIF2CExaZrQLAAW67EhXec+oDV7Yrhq6znPnztncZXBdBamHLsD0aghM2CajXQAo0FVHui4bvLA5nSe8rZsgLRnrul9av5/97Gf/+/WFCxcmPMn8CEzGdv78+X1fv3Xr1pZPshmjXQAo0E1HSr+Wu9Hl3+tMhzWXznPx97S9u30HdZ6taz5Ih9rUdb+0PnsDdL//LkzXN5fAZDq9BuZBjHYBoEDzHSl9Oqob3ft5OlPYvrE7z8X1a186ajpIx3gAgw3eaa0aoId9nVCFccxtZLsqo10AKNBkR+pRgBzGEhKr8Nzdg+k819NkkI7NBu80Nh3rHnYtgQoHE5jDMNoFgALNdaTGuv0ZshPd79q60gft7Ox4L+kMtdx9nj9/vurNXR3pIYT2+MYM0eU/Y/EBMDRBCgAFmhntTtUdWjwax1TdoSUklnnuLkPQkTJLxrzAUAQpABRoIkhrWPqp4Qy9qKUbnPMC0s7OjnHmzNy6davqzdejnD9/vtrN46rvkQqvvtQaWp7TC5RooiMFgFoJ0jVcunRJl7yhWrvRvVo5J8PygApKVDvaFVh9aDGYvEUG6lXjU450pABQQJBuQLc8Dy120+uyuTs/tXVzPahutNtKSHni0dF6CCJjXuAoOlIAKFBdR0r7euhEAVZVVUfaylh3WYtnHlNvIXrhwgVj3Zk4d+6ct8E0oranHFUVpADQmipGu7q69vXWiUbMZ8FosbmrG5uPxeZuTV1dy6oI0tbZ4O3LXAIUGIbRLgAUmDxIjXX70MtSTg9/B2C7Jg/SnvimQBDRPveK21HLPV5BCgAFJls20r31a9GVtrTJq5Nmjm7dulVNV9cyHenA/MzS/2slnFo559g8wB42I0gBoMAko905dGyXLl3yvtJ4sNurbdSrEwWGsNUgnUOAcrCa7p0KUQ6z2Nydw7i79accLc495c9ZNdoFgAKCdEQWj/anGwR6srXRrkBh2VRjXiF+OA+wh/XpSAGggCDdAt34wRbP6N1Gp6gbBcYw+mhXiLCqCxcujDLqFaBs6ty5c7PY3I1o6ylHU27o7kdHCgAF/GBvqjL0EpJuFNpVW+d5kNGD1NN92MRYY15Ws7OzY3OXrWklMA9itAsABYx2qVbJc3qNdKFerXegewlSmrDOvVMhCpsZ+rm7vQXmQYx2AaCAjpSmHLaEpBOlxFzeLzqGuXSeBxGkNGe/Ma8QHV6vz90VmJube2AexGgXAAroSGmWLpTD6Dw3p/NcjyAFmiYwmZrRLgAU0JECTdB5UitBChxqm8/dFZa0yGgXAAroSIGt03nSE0EKjEZgMgdGuwBQQEcKFNN5MmeCFDiSoISDGe0CQAFBCgAFBCkAFBCkAFBAkAJAAUEKAAUEKQAUEKQAUECQAkABQQoABVLOefVPTulORLwx3nE4wtM559NDXUw9JzdoPSPUtAL+jfZlpXquFaQAwIOMdgGggCAFgAKCFAAKCFIAKCBIAaCAIAWAAoIUAAoIUgAoIEgBoMB/AdoZdZAZo4MqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 12 random train images\n",
    "shi.plot_12images(images_train, labels_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "labels_train shape: (14000, 2)\n",
      "labels_test shape: (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train, num_classes=2)\n",
    "labels_test = np_utils.to_categorical(labels_test_or, num_classes=2)\n",
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# filename for model \n",
    "model_fname = os.path.join(original_data_path, 'Models','model.h5')\n",
    "\n",
    "# load the trained model\n",
    "model = load_model(model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_layer1_input to have 4 dimensions, but got array with shape (2000, 4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-734bfee9dbaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_layer1_input to have 4 dimensions, but got array with shape (2000, 4096)"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(images_test, labels_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up 10 random images and classify them using the trained model\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "figsize = (8, 6)\n",
    "plt.figure(figsize=figsize)\n",
    "j=0\n",
    "nim = len(labels_test_or)\n",
    "\n",
    "for _ in range(10):\n",
    "    ind=int(np.random.randint(1,nim))\n",
    "    img=images_test[ind,:]\n",
    "    img=np.reshape(img,(64,64))\n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    label=labels_test_or[ind]\n",
    "       \n",
    "    predictions = model.predict(X);\n",
    "    pred = np.argmax(predictions) \n",
    "    \n",
    "    j = j+1\n",
    "    plt.subplot(2, 5, j)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('n=%d n̂=%d' % (label, pred))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the indicies of the missclassified images and display some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(images_test)\n",
    "indices_wrong = [i for i,v in enumerate(predictions) if np.argmax(predictions[i])!=np.argmax(labels_test[i])]\n",
    "print('Missclassified images: ', len(indices_wrong)/len(labels_test)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 10 missclassified images \n",
    "\n",
    "for i in range(10):\n",
    "      \n",
    "    ind = indices_wrong[i]\n",
    "    img = images_test[ind].reshape(img_rows, img_cols)\n",
    "    lab = np.argmax(labels_test[ind])+1 # we subtracted 1 before\n",
    "    pred = np.argmax(predictions[ind])+1\n",
    "    \n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) \n",
    "    plt.title('n=%d n̂=%d' % (lab, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of top analysis methods by preparing tuples containing the methods' string identifiers used by innvestigate.analyzer.create_analyzer(...), some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_range = [0, 1]\n",
    "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(images_test, input_range)\n",
    "def input_postprocessing(X):\n",
    "    #return revert_preprocessing(X) / 255\n",
    "    return 1-X\n",
    "\n",
    "\n",
    "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
    "ri = input_range[0]  # reference input\n",
    "\n",
    "# Configure analysis methods and properties\n",
    "methods = [\n",
    "    # NAME            OPT.PARAMS                POSTPROC FXN               TITLE\n",
    "\n",
    "    # Show input\n",
    "    (\"input\",         {},                       input_postprocessing,      \"Input\"),\n",
    "\n",
    "    # Signal\n",
    " #   (\"pattern.net\",   {\"pattern_type\": \"relu\"}, mnistutils.bk_proj,        \"PatternNet\"), \n",
    "\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",  {\"pattern_type\": \"relu\"}, mnistutils.heatmap,        \"PatternAttribution\"),\n",
    "       \n",
    "    (\"deep_taylor.bounded\",   {\"low\": input_range[0],\"high\": input_range[1]}, mnistutils.heatmap,        \"DeepTaylor\"),\n",
    "    \n",
    "#    (\"input_t_gradient\",     {},                        mnistutils.heatmap,        \"Input * Gradient\"),\n",
    "    \n",
    "#    (\"integrated_gradients\", {\"reference_inputs\": ri},  mnistutils.heatmap,        \"Integrated Gradients\"), \n",
    "\n",
    "#    (\"lrp.z\",                {},                        mnistutils.heatmap,        \"LRP-Z\"),\n",
    "]\n",
    "    \n",
    "print('Considered number of explainability methods:', len(methods)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop instantiates the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model without trailing softmax\n",
    "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "path_to_analyzers = \"/home/elena/eStep/XAI/Data/TrianglesAndSquaresRotationScale/Analyzers/\"  \n",
    "\n",
    "\n",
    "# Create analyzers.\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    fname = os.path.join(path_to_analyzers, method[0]+'.npz')\n",
    "    \n",
    "    analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
    "                                            model_wo_softmax, # model without softmax output\n",
    "                                            neuron_selection_mode=\"index\",\n",
    "                                            **method[1])     \n",
    "    \n",
    "    if os.path.isfile(fname) :\n",
    "        print(\"Analyzer\", method[0], \"exists! Loading...\")\n",
    "        analyzer = analyzer.load_npz(fname)\n",
    "    else:\n",
    "        print(\"Analyzer\", method[0], \" doesn't exist! Creating and possibly Training and [Saving]...\")\n",
    "        # Some analyzers require training.\n",
    "        analyzer.fit(images_train, batch_size=50, verbose=1)\n",
    "        if (method[0]=='pattern.net') or (method[0]=='pattern.attribution'):\n",
    "            analyzer.save_npz(fname)\n",
    "    \n",
    "    analyzers.append(analyzer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze random set of test images with the different analyzers on all output neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = len(labels_test_or)\n",
    "ntim = 25\n",
    "ind = int(np.random.randint(1,nim-ntim))\n",
    "num_classes = 2\n",
    "\n",
    "test_images = list(zip(images_test[ind:ind+ntim], labels_test_or[ind:ind+ntim]))\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "for image_nr, (x, y) in enumerate(test_images):\n",
    "    y = int(y)\n",
    "    # Add batch axis.\n",
    "    x = x[None, :, :, :]\n",
    "\n",
    "    analysis = np.zeros([num_classes, len(analyzers), 64, 64, 3])\n",
    "    text = []\n",
    "\n",
    "    for ii, output_neuron in enumerate([0, 1]):\n",
    "        # Predict final activations, probabilites, and label.\n",
    "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "        prob = model.predict_on_batch(x)[0]\n",
    "        y_hat = prob.argmax()\n",
    "\n",
    "        # Save prediction info:\n",
    "        text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                     \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                     \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                     \"%s\" % label_to_class_name[output_neuron]\n",
    "                    ))\n",
    "       \n",
    "\n",
    "        for aidx, analyzer in enumerate(analyzers):\n",
    "            # Analyze.\n",
    "            a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "            a = mnistutils.postprocess(a)\n",
    "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "            a = methods[aidx][2](a)\n",
    "            # Store the analysis.\n",
    "            analysis[ii, aidx] = a[0]\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Image nr. {}; prediction: {} \".format(ind+image_nr, y_hat))\n",
    "    # Prepare the grid as rectengular list\n",
    "    grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "            for i in range(analysis.shape[0])]\n",
    "    # Prepare the labels\n",
    "    label, presm, prob, pred = zip(*text)\n",
    "    print(label)\n",
    "    row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "   # row_labels_right = []\n",
    "    row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "    col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "    # Plot the analysis.\n",
    "    file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "   # print(file_name)\n",
    "    if file_name is not None:\n",
    "        file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]   \n",
    "    n_rows = len(grid)\n",
    "    n_cols = len(grid[0])\n",
    "    figsize = (2*n_cols, 2*(n_rows+1))\n",
    "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, figsize=figsize, file_name=file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze subset of missclassified images with the different analyzers on all output neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = len(indices_wrong)\n",
    "ntim = 25\n",
    "indices = indices_wrong[0:ntim]\n",
    "num_classes = 2\n",
    "\n",
    "test_images = list(zip(images_test[indices], labels_test_or[indices]))\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "for image_nr, (x, y) in enumerate(test_images):\n",
    "    y = int(y)\n",
    "    # Add batch axis.\n",
    "    x = x[None, :, :, :]\n",
    "\n",
    "    analysis = np.zeros([num_classes, len(analyzers), 64, 64, 3])\n",
    "    text = []\n",
    "\n",
    "    for ii, output_neuron in enumerate([0, 1]):\n",
    "        # Predict final activations, probabilites, and label.\n",
    "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "        prob = model.predict_on_batch(x)[0]\n",
    "        y_hat = prob.argmax()\n",
    "\n",
    "        # Save prediction info:\n",
    "        text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                     \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                     \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                     \"%s\" % label_to_class_name[output_neuron]\n",
    "                    ))\n",
    "       \n",
    "\n",
    "        for aidx, analyzer in enumerate(analyzers):\n",
    "            # Analyze.\n",
    "            a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "            a = mnistutils.postprocess(a)\n",
    "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "            a = methods[aidx][2](a)\n",
    "            # Store the analysis.\n",
    "            analysis[ii, aidx] = a[0]\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Image nr. {}; prediction: {} \".format(ind+image_nr, y_hat))\n",
    "    # Prepare the grid as rectengular list\n",
    "    grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "            for i in range(analysis.shape[0])]\n",
    "    # Prepare the labels\n",
    "    label, presm, prob, pred = zip(*text)\n",
    "    print(label)\n",
    "    row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "   # row_labels_right = []\n",
    "    row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "    col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "    # Plot the analysis.\n",
    "    file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "   # print(file_name)\n",
    "    if file_name is not None:\n",
    "        file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]   \n",
    "    n_rows = len(grid)\n",
    "    n_cols = len(grid[0])\n",
    "    figsize = (2*n_cols, 2*(n_rows+1))\n",
    "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, figsize=figsize, file_name=file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
