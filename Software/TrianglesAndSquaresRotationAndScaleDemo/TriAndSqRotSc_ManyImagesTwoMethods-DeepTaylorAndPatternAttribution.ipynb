{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two analysers - DeepTaylor and PatternAttribution of the classification model on many images of the  on Triangles and Squares (Rotaion & Scaling) dataset using iNNvestigate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils_mnist.py\")\n",
    "eutils = imp.load_source(\"utils\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils.py\")\n",
    "\n",
    "from code import shape_images as shi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "# data paths\n",
    "original_data_path = \"/home/elena/eStep/XAI/Data/TrianglesAndSquaresRotationScale\"\n",
    "\n",
    "train_data_fname = os.path.join(original_data_path, 'split_npz','train_data.npz')\n",
    "test_data_fname = os.path.join(original_data_path, 'split_npz','test_data.npz')\n",
    "\n",
    "# loading\n",
    "train_data = np.load(train_data_fname)\n",
    "test_data = np.load(test_data_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  (14000, 4096) and labels:  (14000,)\n",
      "Size of testing data:  (2000, 4096) and labels:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "images_train = train_data['images_train']\n",
    "labels_train = train_data['labels_train']\n",
    "images_test = test_data['images_test']\n",
    "labels_test_or = test_data['labels_test']\n",
    "\n",
    "print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "print(\"Size of testing data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test_or))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  (14000, 64, 64, 1)\n",
      "Size of testing data:  (2000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "    images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    images_train = images_train.reshape(images_train.shape[0], img_rows, img_cols, 1)\n",
    "    images_test = images_test.reshape(images_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "print(\"Size of training data: \", np.shape(images_train))\n",
    "print(\"Size of testing data: \", np.shape(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 12 random train images\n",
    "shi.plot_12images(images_train, labels_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "labels_train shape: (14000, 2)\n",
      "labels_test shape: (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "labels_train = np_utils.to_categorical(labels_train, num_classes=2)\n",
    "labels_test = np_utils.to_categorical(labels_test_or, num_classes=2)\n",
    "print(labels_train)\n",
    "print('labels_train shape:', labels_train.shape)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# filename for model \n",
    "model_fname = os.path.join(original_data_path, 'Models','model.h5')\n",
    "\n",
    "# load the trained model\n",
    "model = load_model(model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(images_test, labels_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up 10 random images and classify them using the trained model\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "figsize = (8, 6)\n",
    "plt.figure(figsize=figsize)\n",
    "j=0\n",
    "nim = len(labels_test_or)\n",
    "\n",
    "for _ in range(10):\n",
    "    ind=int(np.random.randint(1,nim))\n",
    "    img=images_test[ind,:]\n",
    "    img=np.reshape(img,(64,64))\n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    label=labels_test_or[ind]\n",
    "       \n",
    "    predictions = model.predict(X);\n",
    "    pred = np.argmax(predictions) \n",
    "    \n",
    "    j = j+1\n",
    "    plt.subplot(2, 5, j)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('n=%d n̂=%d' % (label, pred))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the indicies of the missclassified images and display some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(images_test)\n",
    "indices_wrong = [i for i,v in enumerate(predictions) if np.argmax(predictions[i])!=np.argmax(labels_test[i])]\n",
    "print('Missclassified images: ', len(indices_wrong)/len(labels_test)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 10 missclassified images \n",
    "\n",
    "for i in range(10):\n",
    "      \n",
    "    ind = indices_wrong[i]\n",
    "    img = images_test[ind].reshape(img_rows, img_cols)\n",
    "    lab = np.argmax(labels_test[ind])+1 # we subtracted 1 before\n",
    "    pred = np.argmax(predictions[ind])+1\n",
    "    \n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img*255,cmap=cm.gray, vmin=0, vmax=255)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([]) \n",
    "    plt.title('n=%d n̂=%d' % (lab, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of top analysis methods by preparing tuples containing the methods' string identifiers used by innvestigate.analyzer.create_analyzer(...), some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_range = [0, 1]\n",
    "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(images_test, input_range)\n",
    "def input_postprocessing(X):\n",
    "    #return revert_preprocessing(X) / 255\n",
    "    return 1-X\n",
    "\n",
    "\n",
    "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
    "ri = input_range[0]  # reference input\n",
    "\n",
    "# Configure analysis methods and properties\n",
    "methods = [\n",
    "    # NAME            OPT.PARAMS                POSTPROC FXN               TITLE\n",
    "\n",
    "    # Show input\n",
    "    (\"input\",         {},                       input_postprocessing,      \"Input\"),\n",
    "\n",
    "    # Signal\n",
    " #   (\"pattern.net\",   {\"pattern_type\": \"relu\"}, mnistutils.bk_proj,        \"PatternNet\"), \n",
    "\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",  {\"pattern_type\": \"relu\"}, mnistutils.heatmap,        \"PatternAttribution\"),\n",
    "       \n",
    "    (\"deep_taylor.bounded\",   {\"low\": input_range[0],\"high\": input_range[1]}, mnistutils.heatmap,        \"DeepTaylor\"),\n",
    "    \n",
    "#    (\"input_t_gradient\",     {},                        mnistutils.heatmap,        \"Input * Gradient\"),\n",
    "    \n",
    "#    (\"integrated_gradients\", {\"reference_inputs\": ri},  mnistutils.heatmap,        \"Integrated Gradients\"), \n",
    "\n",
    "#    (\"lrp.z\",                {},                        mnistutils.heatmap,        \"LRP-Z\"),\n",
    "]\n",
    "    \n",
    "print('Considered number of explainability methods:', len(methods)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop instantiates the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model without trailing softmax\n",
    "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "path_to_analyzers = \"/home/elena/eStep/XAI/Data/TrianglesAndSquaresRotationScale/Analyzers/\"  \n",
    "\n",
    "\n",
    "# Create analyzers.\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    fname = os.path.join(path_to_analyzers, method[0]+'.npz')\n",
    "    \n",
    "    analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
    "                                            model_wo_softmax, # model without softmax output\n",
    "                                            neuron_selection_mode=\"index\",\n",
    "                                            **method[1])     \n",
    "    \n",
    "    if os.path.isfile(fname) :\n",
    "        print(\"Analyzer\", method[0], \"exists! Loading...\")\n",
    "        analyzer = analyzer.load_npz(fname)\n",
    "    else:\n",
    "        print(\"Analyzer\", method[0], \" doesn't exist! Creating and possibly Training and [Saving]...\")\n",
    "        # Some analyzers require training.\n",
    "        analyzer.fit(images_train, batch_size=50, verbose=1)\n",
    "        if (method[0]=='pattern.net') or (method[0]=='pattern.attribution'):\n",
    "            analyzer.save_npz(fname)\n",
    "    \n",
    "    analyzers.append(analyzer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze random set of test images with the different analyzers on all output neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = len(labels_test_or)\n",
    "ntim = 25\n",
    "ind = int(np.random.randint(1,nim-ntim))\n",
    "num_classes = 2\n",
    "\n",
    "test_images = list(zip(images_test[ind:ind+ntim], labels_test_or[ind:ind+ntim]))\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "for image_nr, (x, y) in enumerate(test_images):\n",
    "    y = int(y)\n",
    "    # Add batch axis.\n",
    "    x = x[None, :, :, :]\n",
    "\n",
    "    analysis = np.zeros([num_classes, len(analyzers), 64, 64, 3])\n",
    "    text = []\n",
    "\n",
    "    for ii, output_neuron in enumerate([0, 1]):\n",
    "        # Predict final activations, probabilites, and label.\n",
    "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "        prob = model.predict_on_batch(x)[0]\n",
    "        y_hat = prob.argmax()\n",
    "\n",
    "        # Save prediction info:\n",
    "        text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                     \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                     \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                     \"%s\" % label_to_class_name[output_neuron]\n",
    "                    ))\n",
    "       \n",
    "\n",
    "        for aidx, analyzer in enumerate(analyzers):\n",
    "            # Analyze.\n",
    "            a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "            a = mnistutils.postprocess(a)\n",
    "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "            a = methods[aidx][2](a)\n",
    "            # Store the analysis.\n",
    "            analysis[ii, aidx] = a[0]\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Image nr. {}; prediction: {} \".format(ind+image_nr, y_hat))\n",
    "    # Prepare the grid as rectengular list\n",
    "    grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "            for i in range(analysis.shape[0])]\n",
    "    # Prepare the labels\n",
    "    label, presm, prob, pred = zip(*text)\n",
    "    print(label)\n",
    "    row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "   # row_labels_right = []\n",
    "    row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "    col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "    # Plot the analysis.\n",
    "    file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "   # print(file_name)\n",
    "    if file_name is not None:\n",
    "        file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]   \n",
    "    n_rows = len(grid)\n",
    "    n_cols = len(grid[0])\n",
    "    figsize = (2*n_cols, 2*(n_rows+1))\n",
    "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, figsize=figsize, file_name=file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze subset of missclassified images with the different analyzers on all output neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = len(indices_wrong)\n",
    "ntim = 25\n",
    "indices = indices_wrong[0:ntim]\n",
    "num_classes = 2\n",
    "\n",
    "test_images = list(zip(images_test[indices], labels_test_or[indices]))\n",
    "label_to_class_name = [str(i) for i in range(num_classes)]\n",
    "\n",
    "for image_nr, (x, y) in enumerate(test_images):\n",
    "    y = int(y)\n",
    "    # Add batch axis.\n",
    "    x = x[None, :, :, :]\n",
    "\n",
    "    analysis = np.zeros([num_classes, len(analyzers), 64, 64, 3])\n",
    "    text = []\n",
    "\n",
    "    for ii, output_neuron in enumerate([0, 1]):\n",
    "        # Predict final activations, probabilites, and label.\n",
    "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "        prob = model.predict_on_batch(x)[0]\n",
    "        y_hat = prob.argmax()\n",
    "\n",
    "        # Save prediction info:\n",
    "        text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                     \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                     \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                     \"%s\" % label_to_class_name[output_neuron]\n",
    "                    ))\n",
    "       \n",
    "\n",
    "        for aidx, analyzer in enumerate(analyzers):\n",
    "            # Analyze.\n",
    "            a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "            a = mnistutils.postprocess(a)\n",
    "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "            a = methods[aidx][2](a)\n",
    "            # Store the analysis.\n",
    "            analysis[ii, aidx] = a[0]\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Image nr. {}; prediction: {} \".format(ind+image_nr, y_hat))\n",
    "    # Prepare the grid as rectengular list\n",
    "    grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "            for i in range(analysis.shape[0])]\n",
    "    # Prepare the labels\n",
    "    label, presm, prob, pred = zip(*text)\n",
    "    print(label)\n",
    "    row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "   # row_labels_right = []\n",
    "    row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "    col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "    # Plot the analysis.\n",
    "    file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "   # print(file_name)\n",
    "    if file_name is not None:\n",
    "        file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]   \n",
    "    n_rows = len(grid)\n",
    "    n_cols = len(grid[0])\n",
    "    figsize = (2*n_cols, 2*(n_rows+1))\n",
    "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, figsize=figsize, file_name=file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
