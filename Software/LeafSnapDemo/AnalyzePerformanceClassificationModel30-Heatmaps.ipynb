{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the performance of the classification model for 30 tree species based on LeafSnap data subset - heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-vis\n",
      "  Downloading keras_vis-0.4.1-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: keras in /home/elena/anaconda3/lib/python3.6/site-packages (from keras-vis) (2.2.4)\n",
      "Requirement already satisfied: scikit-image in /home/elena/anaconda3/lib/python3.6/site-packages (from keras-vis) (0.14.2)\n",
      "Requirement already satisfied: six in /home/elena/anaconda3/lib/python3.6/site-packages (from keras-vis) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in /home/elena/anaconda3/lib/python3.6/site-packages (from keras-vis) (2.2.3)\n",
      "Requirement already satisfied: h5py in /home/elena/anaconda3/lib/python3.6/site-packages (from keras-vis) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/elena/anaconda3/lib/python3.6/site-packages (from keras->keras-vis) (1.0.7)\n",
      "Requirement already satisfied: pyyaml in /home/elena/anaconda3/lib/python3.6/site-packages (from keras->keras-vis) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/elena/anaconda3/lib/python3.6/site-packages (from keras->keras-vis) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/elena/anaconda3/lib/python3.6/site-packages (from keras->keras-vis) (1.18.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/elena/anaconda3/lib/python3.6/site-packages (from keras->keras-vis) (1.1.2)\n",
      "Requirement already satisfied: networkx>=1.8 in /home/elena/anaconda3/lib/python3.6/site-packages (from scikit-image->keras-vis) (2.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /home/elena/anaconda3/lib/python3.6/site-packages (from scikit-image->keras-vis) (5.2.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/elena/anaconda3/lib/python3.6/site-packages (from scikit-image->keras-vis) (0.5.2)\n",
      "Requirement already satisfied: dask[array]>=1.0.0 in /home/elena/anaconda3/lib/python3.6/site-packages (from scikit-image->keras-vis) (1.1.1)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /home/elena/anaconda3/lib/python3.6/site-packages (from scikit-image->keras-vis) (0.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/elena/anaconda3/lib/python3.6/site-packages (from matplotlib->keras-vis) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/elena/anaconda3/lib/python3.6/site-packages (from matplotlib->keras-vis) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/elena/anaconda3/lib/python3.6/site-packages (from matplotlib->keras-vis) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/elena/anaconda3/lib/python3.6/site-packages (from matplotlib->keras-vis) (2.7.3)\n",
      "Requirement already satisfied: pytz in /home/elena/anaconda3/lib/python3.6/site-packages (from matplotlib->keras-vis) (2018.4)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /home/elena/anaconda3/lib/python3.6/site-packages (from networkx>=1.8->scikit-image->keras-vis) (4.3.0)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /home/elena/anaconda3/lib/python3.6/site-packages (from dask[array]>=1.0.0->scikit-image->keras-vis) (0.9.0)\n",
      "Requirement already satisfied: setuptools in /home/elena/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->keras-vis) (47.1.1)\n",
      "Installing collected packages: keras-vis\n",
      "Successfully installed keras-vis-0.4.1\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/elena/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-420d77f6c4b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize_cam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vis'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from vis.utils import utils\n",
    "from vis.visualization import visualize_cam\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "\n",
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the relevant data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_path = \"/home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/\"\n",
    "dataset_info_file = os.path.join(original_data_path, \"leafsnap-dataset-30subset-images.txt\")\n",
    "\n",
    "img_info = pd.read_csv(dataset_info_file, sep=\"\\t\")\n",
    "img_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model_file = model_fname = os.path.join(original_data_path, 'Models','leafnet.h5')\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize interesting regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient weighted class activation maps\n",
    "\n",
    "We predict the class of one image with our network. From the output, we select the column corresponding to the class that the highest probability was assigned to. Next, we get the output from the final convolutional layer (the final convolutional feature map, eg (14,14,512)). We then compute the gradient of our selected class’s output with respect to the feature map (In how far does changing the values in the feature map change the output for our selected class?).\n",
    "\n",
    "From these gradients, we select the maximum gradient per channel of the feature map (so the maximum gradient for each filter (512,) --> like a global max pooling layer: collapse each filter (each channel) so each feature that is detected (by the corresponding filter) in one node ((1,1,512) or (512,)) and multiply the first two dimensions oft he feature map with it (so multiply each of the 14x14 values per each of the 512 channels with the one maximum gradient value for the corresponding channel). From this, we obtain the weighted feature map (14, 14, 512), where each of the 14x14 values inside each channel is weighted by the maximum gradient of this channel.\n",
    "\n",
    "We then average across the channel axis into a (14, 14) heatmap (so we have one average value for each of the first two dimensions of the weighted feature map across all channels). The higher a value in this heatmap, the more does the output for our selected class depend on it.\n",
    "\n",
    "Then, we set all negative entries in the heatmap to zero and normalize all values by dividing them by the maximum value inside the heatmap, so that now values range from 0 to 1. Next, we resize the heatmap to the size of the image we generated the heatmap for (the input image we predicted a class for). Then, we multiply each of the heatmap’s entries by 255, to obtain a grayscale image. This is then pseudocolored. Finally, the heatmap is imposed on the original image.\n",
    "\n",
    "From this, we can see, which parts of the image the model mainly used to come up with a classification, as\n",
    "we highlight the feature map regions that cause the most change in the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(img_array, model, layer_output, layer_conv, img):\n",
    "    '''\n",
    "    Computes a gradient weighted class activation map for an image by weighing the final convolutional \n",
    "    feature map with the gradient of the predicted class with respect to the channel and then averaging \n",
    "    along the channel (filter) axis to visualize which image regions are important for classifying the\n",
    "    image.\n",
    "    \n",
    "    Input:\n",
    "    - img_array: normalized rgb array of an image with shape (w,h,c) as expected by the model (assuming\n",
    "      the amount of training examples is given on the first axis for the model input)\n",
    "    - model: model to base the class activation map on\n",
    "    - layer_ouput: name of the model's softmax output layer (str)\n",
    "    - layer_conv: name of the final convolutional layer (this feature map is used) (str)\n",
    "    - img: filename (with path) of the image corresponding to img_array, of any size\n",
    "    \n",
    "    Returns:\n",
    "    - img with the class activation map superimposed on it \n",
    "    '''\n",
    "    \n",
    "    #expand img_array to fit into model: (1,w,h,c)\n",
    "    x = np.expand_dims(img_array, axis=0)\n",
    "    #predict the corresponding class\n",
    "    pred_class = np.argmax(model.predict(x))\n",
    "    layer_output_name = layer_output\n",
    "    layer_conv_name = layer_conv\n",
    "    #get indices of the relevant layers\n",
    "    output_layer_idx = [idx for idx, layer in enumerate(model.layers) if layer.name == layer_output_name][0]\n",
    "    conv_layer_idx = [idx for idx, layer in enumerate(model.layers) if layer.name == layer_conv_name][0]\n",
    "    #change softmax layer to linear activation layer to obtain better results\n",
    "    model.layers[output_layer_idx].activation = activations.linear\n",
    "    #apply changes (to new model instance, original model stays untouched)\n",
    "    model_maps = utils.apply_modifications(model)\n",
    "    #generate class activation map\n",
    "    heatmap = visualize_cam(model=model_maps, layer_idx=output_layer_idx, filter_indices=[pred_class], seed_input=x, penultimate_layer_idx=conv_layer_idx)\n",
    "    #read image the map is to be superimposed on\n",
    "    img = cv2.imread(img)\n",
    "    #resize map to the size of img\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    #superimpose\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "    \n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frame containing one lab picture per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_info_lab = img_info[img_info[\"source\"] == \"lab\"]\n",
    "\n",
    "k = 0\n",
    "for index, row in img_info_lab.iterrows():\n",
    "    if k == 0:\n",
    "        if row[\"labels_integer\"] == k:\n",
    "            example_per_label_lab = row\n",
    "            example_per_label_lab = pd.DataFrame([example_per_label_lab])\n",
    "            k += 1\n",
    "    elif k == 30:\n",
    "        break\n",
    "    else:\n",
    "        if row[\"labels_integer\"] == k:\n",
    "            example_per_label_lab = example_per_label_lab.append(row)\n",
    "            k +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate heatmap for each lab example (one per class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"heatmaps/lab/\"\n",
    "col_index_path = example_per_label_lab.columns.get_loc(\"image_path\")\n",
    "col_index_filename = example_per_label_lab.columns.get_loc(\"filename\")\n",
    "col_index_label = example_per_label_lab.columns.get_loc(\"species\")\n",
    "\n",
    "for i in range(len(example_per_label_lab)):\n",
    "  path = example_per_label_lab.iloc[i, col_index_path]\n",
    "  img = cv2.imread(path)\n",
    "  img = cv2.resize(img, (64, 64))\n",
    "  img = img/255\n",
    "  heatmap = generate_heatmap(img, model, \"dense_2\", \"activation_2\", path)\n",
    "  filename = example_per_label_lab.iloc[i, col_index_label] + \"_heatmap_\" +  example_per_label_lab.iloc[i, col_index_filename]\n",
    "  cv2.imwrite(output_path + filename, heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frame containing one field picture per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_info_field = img_info[img_info[\"source\"] == \"field\"]\n",
    "\n",
    "k = 0\n",
    "for index, row in img_info_field.iterrows():\n",
    "    if k == 0:\n",
    "        if row[\"labels_integer\"] == k:\n",
    "            example_per_label_field = row\n",
    "            example_per_label_field = pd.DataFrame([example_per_label_field])\n",
    "            k += 1\n",
    "    elif k == 30:\n",
    "        break\n",
    "    else:\n",
    "        if row[\"labels_integer\"] == k:\n",
    "            example_per_label_field = example_per_label_field.append(row)\n",
    "            k +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"heatmaps/field/\"\n",
    "col_index_path = example_per_label_field.columns.get_loc(\"image_path\")\n",
    "col_index_filename = example_per_label_field.columns.get_loc(\"filename\")\n",
    "col_index_label = example_per_label_field.columns.get_loc(\"species\")\n",
    "\n",
    "for i in range(len(example_per_label_field)):\n",
    "  path = example_per_label_field.iloc[i, col_index_path]\n",
    "  img = cv2.imread(path)\n",
    "  img = cv2.resize(img, (64, 64))\n",
    "  img = img/255\n",
    "  heatmap = generate_heatmap(img, model, \"dense_2\", \"activation_2\", path)\n",
    "  filename = example_per_label_field.iloc[i, col_index_label] + \"_heatmap_\" +  example_per_label_field.iloc[i, col_index_filename]\n",
    "  cv2.imwrite(output_path + filename, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
