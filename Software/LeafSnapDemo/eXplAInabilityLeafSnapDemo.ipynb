{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability Demo on Simple scientific dataset\n",
    "\n",
    "*At the moment this is work in progress and in the experimental phase. If the experiment is successsful, e.g. we get meaningful heatmaps for the task, this will turn into a real demo!*\n",
    "\n",
    "**The purpose of this demo is to show the ability of DNN explainability method(s) to generate meanfingful heatmaps for the relevance of the input image pixels to the output resut of a CNN model. The task is chosen to be classification of images of leaves of 20 species of North American trees. The original dataset comes from LeafSnap - an app from 2012 for automatic classification of 185 species of trees. For this demo a subset of images taken in a lab(Smitsonian Insittute) from 20 species is used.**\n",
    "\n",
    "The explainability tool [iNNvestigate](https://github.com/albermax/innvestigate) is chosen as it offers open source implementatons of several explainability methods. Since it supports [Keras](https://keras.io/), the framework (with [Tensorflow](https://www.tensorflow.org/) as backend) is used to genrate the CNN model(s), though our vision is to go for at least [PyTorch](https://pytorch.org/) deep learning library and the related [Captum](https://captum.ai/) explainability library and definitely towards using DNN model standards such as [ONNX](https://onnx.ai/). This [list of explainability tools](https://github.com/NLeSC/XAI/blob/master/State-of-the-art/AI_Explainability_OSTools.docx) sumamrizes the availability of explainability tools.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "The original dataset has been downloaded from [kaggle.com](https://www.kaggle.com/xhlulu/leafsnap-dataset) as [leafsnap.com](leafsnap.com/dataset) is not available any more. It is stored at [SURF drive](https://surfdrive.surf.nl/files/index.php/s/MoCVal7gxS4aX51?path=%2Fdata%2FLeafSnap). There are 30 866 (~31k) color images of different sizes. The dataset covers all 185 tree species from the Northeastern United States.\n",
    "The original images of leaves taken from two different sources:\n",
    "  * \"Lab\" images, consisting of high-quality images taken of pressed leaves,\n",
    "    from the Smithsonian collection. \n",
    "  * \"Field\" images, consisting of \"typical\" images taken by mobile devices\n",
    "    (iPhones mostly) in outdoor environments. \n",
    "    \n",
    "For the purpose of this demo a subset of 20 species of lab and field images has been selected. The lab images have been cropped semi-manually using IrfanView to remove the riles and color calibration image parts. This results in a small dataset of 3283 images.   \n",
    "    \n",
    "The notebook [DataPreparation](https://github.com/NLeSC/XAI/blob/master/Software/LeafSnapDemo/Data_preparation.ipynb) (based on a [student project notebook](https://github.com/Mathis1993/Leaf-Classification-CNN/blob/master/Complete_Workflow.ipynb)) is used to load the cropped images resize to images to 64x64, normalize the data and save the files as numpy compressed (NPZ). The resulting files are also stored in a subfolder on [SURF drive](https://surfdrive.surf.nl/files/index.php/s/MoCVal7gxS4aX51?path=%2Fdata%2FLeafSnap%2FDataset-20-Subset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and tetsing\n",
    "\n",
    "The generated data per dataset have been split in ... images for training, ... for validaiton and ... for testing. \n",
    "Notebook for the [model training and testing]()\n",
    "\n",
    "The obtained accuracies are as follows: 91.77% on he train set and 73.5% on the validation set.\n",
    "\n",
    "The obtained test accuracy:66.8 %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability heatmaps\n",
    "\n",
    "The links to the notebooks for generating explainability heatmaps:\n",
    "\n",
    "\n",
    "\n",
    "-----------------------\n",
    "### Experiments\n",
    "\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "#### Experiment1: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
