{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to classify 20 tree species based on LeafSnap data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from code import data as d\n",
    "from code import model as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_path = \"/home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-20subset/\"\n",
    "images_fname = os.path.join(original_data_path, \"images.npz\")\n",
    "labels_fname = os.path.join(original_data_path, \"labels.npz\")\n",
    "info_fname_rand = os.path.join(original_data_path, \"leafsnap-dataset-20subset-images-enhanced-randomized.txt\")\n",
    "\n",
    "# load data\n",
    "image_data = np.load(images_fname)\n",
    "labels_data = np.load(labels_fname)\n",
    "info_data = pd.read_csv(info_fname_rand)\n",
    "\n",
    "images = image_data['images']\n",
    "labels_one_hot = labels_data['labels_one_hot']\n",
    "\n",
    "\n",
    "print('Image size: ', np.shape(images))\n",
    "print('Labels one hot size: ', np.shape(labels_one_hot))\n",
    "\n",
    "nim = len(labels_one_hot)\n",
    "print('Number of images: ', nim)\n",
    "\n",
    "info_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[images_train, images_val, images_test, \n",
    " labels_one_hot_train, labels_one_hot_val, labels_one_hot_test,\n",
    " end_train_ind, end_val_ind] = d.split_data(images,labels_one_hot)\n",
    "print('Image size - train set: ', np.shape(images_train))\n",
    "print('Labels size - train set: ', np.shape(labels_one_hot_train)) \n",
    "print('Image size - valid. set: ', np.shape(images_val))\n",
    "print('Labels size - valid. set: ', np.shape(labels_one_hot_val)) \n",
    "print('Image size - test set: ', np.shape(images_test))\n",
    "print('Labels size - test set: ', np.shape(labels_one_hot_test)) \n",
    "\n",
    "print('Indicies: ', end_train_ind,', ', end_val_ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting some of of the info data\n",
    "\n",
    "labels_train = info_data.loc[:end_train_ind, \"label\"]\n",
    "sources_train = info_data.loc[:end_train_ind, \"source\"]\n",
    "\n",
    "labels_numeric_test = info_data.loc[end_val_ind:nim, \"label_numeric\"]\n",
    "labels_test = info_data.loc[end_val_ind:nim, \"label\"]\n",
    "filenames_test = info_data.loc[end_val_ind:nim, \"filename\"]\n",
    "sources_test = info_data.loc[end_val_ind:nim, \"source\"]\n",
    "path_test = info_data.loc[end_val_ind:nim, \"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random train images\n",
    "d.plot_12images(images_train, labels_train, sources_train, figsize=(12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "img_channels = 3\n",
    "#print(K.image_data_format())\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    images_train = images_train.reshape(images_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    images_test = images_test.reshape(images_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    images_val = images_val.reshape(images_val.shape[0], img_channels, img_rows, img_cols)\n",
    "    input_shape = (img_channels, img_rows, img_cols)\n",
    "else:\n",
    "    images_train = images_train.reshape(images_train.shape[0], img_rows, img_cols, img_channels)\n",
    "    images_test = images_test.reshape(images_test.shape[0], img_rows, img_cols, img_channels)\n",
    "    images_val = images_val.reshape(images_val.shape[0], img_rows, img_cols, img_channels)\n",
    "    input_shape = (img_rows, img_cols, img_channels)\n",
    "print(\"Size of training data: \", np.shape(images_train))\n",
    "print(\"Size of validation data: \", np.shape(images_val))\n",
    "print(\"Size of testing data: \", np.shape(images_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m.generate_model(input_shape, 20)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# autosave best Model\n",
    "best_model_file = model_fname = os.path.join(original_data_path, 'Models','leafnet.h5')\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "print('Training model...')\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "model, results = m.train_model(model, images_train, labels_one_hot_train,\n",
    "                             images_val, labels_one_hot_val, \n",
    "                             batch_size, epochs, best_model)\n",
    "print('Traing finished.')\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(images_test, labels_one_hot_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(results.history['acc'])\n",
    "plt.plot(results.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid.'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid.'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
