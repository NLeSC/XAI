{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to classify 30 tree species based on LeafSnap data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from code import data as d\n",
    "from code import model as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and split into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size:  (6136, 64, 64, 3)\n",
      "Labels one hot size:  (6136, 30)\n",
      "Number of images:  6136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>label_numeric</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>pi0057-05-1.jpg</td>\n",
       "      <td>Tilia americana</td>\n",
       "      <td>lab</td>\n",
       "      <td>15</td>\n",
       "      <td>dataset/images/lab/Auto_cropped/tilia_american...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>wb1194-05-2.jpg</td>\n",
       "      <td>Betula lenta</td>\n",
       "      <td>lab</td>\n",
       "      <td>3</td>\n",
       "      <td>dataset/images/lab/Auto_cropped/betula_lenta/w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>pi0005-05-3.jpg</td>\n",
       "      <td>Ptelea trifoliata</td>\n",
       "      <td>lab</td>\n",
       "      <td>25</td>\n",
       "      <td>dataset/images/lab/Auto_cropped/ptelea_trifoli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>ny1124-02-2.jpg</td>\n",
       "      <td>Broussonettia papyrifera</td>\n",
       "      <td>lab</td>\n",
       "      <td>23</td>\n",
       "      <td>dataset/images/lab/Auto_cropped/broussonettia_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>1249580214_0004.jpg</td>\n",
       "      <td>Magnolia grandiflora</td>\n",
       "      <td>field</td>\n",
       "      <td>8</td>\n",
       "      <td>dataset/images/field/magnolia_grandiflora/1249...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename                     label source  label_numeric  \\\n",
       "6131      pi0057-05-1.jpg           Tilia americana    lab             15   \n",
       "6132      wb1194-05-2.jpg              Betula lenta    lab              3   \n",
       "6133      pi0005-05-3.jpg         Ptelea trifoliata    lab             25   \n",
       "6134      ny1124-02-2.jpg  Broussonettia papyrifera    lab             23   \n",
       "6135  1249580214_0004.jpg      Magnolia grandiflora  field              8   \n",
       "\n",
       "                                                   path  \n",
       "6131  dataset/images/lab/Auto_cropped/tilia_american...  \n",
       "6132  dataset/images/lab/Auto_cropped/betula_lenta/w...  \n",
       "6133  dataset/images/lab/Auto_cropped/ptelea_trifoli...  \n",
       "6134  dataset/images/lab/Auto_cropped/broussonettia_...  \n",
       "6135  dataset/images/field/magnolia_grandiflora/1249...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data_path = \"/home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/\"\n",
    "images_fname = os.path.join(original_data_path, \"images.npz\")\n",
    "labels_fname = os.path.join(original_data_path, \"labels.npz\")\n",
    "info_fname_rand = os.path.join(original_data_path, \"leafsnap-dataset-30subset-images-enhanced-randomized.txt\")\n",
    "\n",
    "# load data\n",
    "image_data = np.load(images_fname)\n",
    "labels_data = np.load(labels_fname)\n",
    "info_data = pd.read_csv(info_fname_rand)\n",
    "\n",
    "images = image_data['images']\n",
    "labels_one_hot = labels_data['labels_one_hot']\n",
    "\n",
    "\n",
    "print('Image size: ', np.shape(images))\n",
    "print('Labels one hot size: ', np.shape(labels_one_hot))\n",
    "\n",
    "nim = len(labels_one_hot)\n",
    "print('Number of images: ', nim)\n",
    "\n",
    "info_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size - train set:  (4295, 64, 64, 3)\n",
      "Labels size - train set:  (4295, 30)\n",
      "Image size - valid. set:  (1227, 64, 64, 3)\n",
      "Labels size - valid. set:  (1227, 30)\n",
      "Image size - test set:  (614, 64, 64, 3)\n",
      "Labels size - test set:  (614, 30)\n",
      "Indicies:  4295 ,  5522\n"
     ]
    }
   ],
   "source": [
    "[images_train, images_val, images_test, \n",
    " labels_one_hot_train, labels_one_hot_val, labels_one_hot_test,\n",
    " end_train_ind, end_val_ind] = d.split_data(images,labels_one_hot)\n",
    "print('Image size - train set: ', np.shape(images_train))\n",
    "print('Labels size - train set: ', np.shape(labels_one_hot_train)) \n",
    "print('Image size - valid. set: ', np.shape(images_val))\n",
    "print('Labels size - valid. set: ', np.shape(labels_one_hot_val)) \n",
    "print('Image size - test set: ', np.shape(images_test))\n",
    "print('Labels size - test set: ', np.shape(labels_one_hot_test)) \n",
    "\n",
    "print('Indicies: ', end_train_ind,', ', end_val_ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting some of of the info data\n",
    "\n",
    "labels_train = info_data.loc[:end_train_ind, \"label\"]\n",
    "sources_train = info_data.loc[:end_train_ind, \"source\"]\n",
    "\n",
    "labels_numeric_test = info_data.loc[end_val_ind:nim, \"label_numeric\"]\n",
    "labels_test = info_data.loc[end_val_ind:nim, \"label\"]\n",
    "filenames_test = info_data.loc[end_val_ind:nim, \"filename\"]\n",
    "sources_test = info_data.loc[end_val_ind:nim, \"source\"]\n",
    "path_test = info_data.loc[end_val_ind:nim, \"path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  (4295, 64, 64, 3)\n",
      "Size of validation data:  (1227, 64, 64, 3)\n",
      "Size of testing data:  (614, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "img_channels = 3\n",
    "#print(K.image_data_format())\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    images_train = images_train.reshape(images_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    images_test = images_test.reshape(images_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    images_val = images_val.reshape(images_val.shape[0], img_channels, img_rows, img_cols)\n",
    "    input_shape = (img_channels, img_rows, img_cols)\n",
    "else:\n",
    "    images_train = images_train.reshape(images_train.shape[0], img_rows, img_cols, img_channels)\n",
    "    images_test = images_test.reshape(images_test.shape[0], img_rows, img_cols, img_channels)\n",
    "    images_val = images_val.reshape(images_val.shape[0], img_rows, img_cols, img_channels)\n",
    "    input_shape = (img_rows, img_cols, img_channels)\n",
    "print(\"Size of training data: \", np.shape(images_train))\n",
    "print(\"Size of validation data: \", np.shape(images_val))\n",
    "print(\"Size of testing data: \", np.shape(images_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_layer1 (Conv2D)       (None, 60, 60, 12)        912       \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer1 (MaxPool (None, 30, 30, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_layer2 (Conv2D)       (None, 26, 26, 24)        7224      \n",
      "_________________________________________________________________\n",
      "maxpooling2d_layer2 (MaxPool (None, 13, 13, 24)        0         \n",
      "_________________________________________________________________\n",
      "dropout_layer1 (Dropout)     (None, 13, 13, 24)        0         \n",
      "_________________________________________________________________\n",
      "flatten_layer1 (Flatten)     (None, 4056)              0         \n",
      "_________________________________________________________________\n",
      "dense_layer1 (Dense)         (None, 200)               811400    \n",
      "_________________________________________________________________\n",
      "dropout_layer2 (Dropout)     (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer2 (Dense)         (None, 30)                6030      \n",
      "=================================================================\n",
      "Total params: 825,566\n",
      "Trainable params: 825,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = m.generate_simpler_model(input_shape, 30)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 4295 samples, validate on 1227 samples\n",
      "Epoch 1/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 3.3860 - acc: 0.0624 - val_loss: 3.3192 - val_acc: 0.1027\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.31924, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 2/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 3.2818 - acc: 0.1069 - val_loss: 3.1317 - val_acc: 0.1483\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.31924 to 3.13172, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 3/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 3.1081 - acc: 0.1418 - val_loss: 2.9080 - val_acc: 0.1972\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.13172 to 2.90805, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 4/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 2.9691 - acc: 0.1783 - val_loss: 2.7737 - val_acc: 0.2478\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.90805 to 2.77373, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 5/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 2.8493 - acc: 0.2063 - val_loss: 2.6735 - val_acc: 0.2942\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.77373 to 2.67347, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 6/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 2.7677 - acc: 0.2235 - val_loss: 2.5476 - val_acc: 0.2991\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.67347 to 2.54758, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 7/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 2.6713 - acc: 0.2529 - val_loss: 2.4653 - val_acc: 0.3219\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.54758 to 2.46526, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 8/400\n",
      "4295/4295 [==============================] - 21s 5ms/step - loss: 2.6155 - acc: 0.2647 - val_loss: 2.4080 - val_acc: 0.3366\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.46526 to 2.40798, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 9/400\n",
      "4295/4295 [==============================] - 19s 4ms/step - loss: 2.5413 - acc: 0.2941 - val_loss: 2.3844 - val_acc: 0.3439\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.40798 to 2.38438, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 10/400\n",
      "4295/4295 [==============================] - 19s 4ms/step - loss: 2.5000 - acc: 0.2908 - val_loss: 2.2917 - val_acc: 0.3578\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.38438 to 2.29169, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 11/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 2.4605 - acc: 0.3003 - val_loss: 2.2961 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.29169\n",
      "Epoch 12/400\n",
      "4295/4295 [==============================] - 19s 4ms/step - loss: 2.4292 - acc: 0.3066 - val_loss: 2.2131 - val_acc: 0.3676\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.29169 to 2.21314, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 13/400\n",
      "4295/4295 [==============================] - 24s 6ms/step - loss: 2.3644 - acc: 0.3232 - val_loss: 2.1691 - val_acc: 0.3757\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.21314 to 2.16907, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 14/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 2.3033 - acc: 0.3336 - val_loss: 2.1751 - val_acc: 0.3961\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.16907\n",
      "Epoch 15/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 2.2846 - acc: 0.3350 - val_loss: 2.0885 - val_acc: 0.3928\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.16907 to 2.08854, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 16/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 2.2576 - acc: 0.3595 - val_loss: 2.0735 - val_acc: 0.4083\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.08854 to 2.07354, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 17/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 2.2295 - acc: 0.3534 - val_loss: 2.0658 - val_acc: 0.4042\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.07354 to 2.06580, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 18/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 2.2170 - acc: 0.3602 - val_loss: 2.0286 - val_acc: 0.4116\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.06580 to 2.02857, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 19/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 2.1559 - acc: 0.3667 - val_loss: 1.9813 - val_acc: 0.4099\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.02857 to 1.98128, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 20/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 2.1267 - acc: 0.3772 - val_loss: 1.9601 - val_acc: 0.4222\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.98128 to 1.96007, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 21/400\n",
      "4295/4295 [==============================] - 19s 4ms/step - loss: 2.1135 - acc: 0.3802 - val_loss: 1.9686 - val_acc: 0.4271\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.96007\n",
      "Epoch 22/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 2.1021 - acc: 0.3858 - val_loss: 1.9386 - val_acc: 0.4450\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.96007 to 1.93858, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 23/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 2.0512 - acc: 0.4012 - val_loss: 1.8708 - val_acc: 0.4474\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.93858 to 1.87081, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 24/400\n",
      "4295/4295 [==============================] - 15s 4ms/step - loss: 2.0125 - acc: 0.4033 - val_loss: 1.8576 - val_acc: 0.4572\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.87081 to 1.85765, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 25/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 2.0092 - acc: 0.4037 - val_loss: 1.9175 - val_acc: 0.4523\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.85765\n",
      "Epoch 26/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.9585 - acc: 0.4217 - val_loss: 1.8223 - val_acc: 0.4621\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.85765 to 1.82235, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 27/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.9410 - acc: 0.4231 - val_loss: 1.8012 - val_acc: 0.4735\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.82235 to 1.80123, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 28/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.9262 - acc: 0.4210 - val_loss: 1.7775 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.80123 to 1.77754, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 29/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.9051 - acc: 0.4345 - val_loss: 1.7971 - val_acc: 0.4719\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.77754\n",
      "Epoch 30/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.9249 - acc: 0.4175 - val_loss: 1.7480 - val_acc: 0.4963\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.77754 to 1.74803, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 31/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295/4295 [==============================] - 15s 3ms/step - loss: 1.8942 - acc: 0.4228 - val_loss: 1.7239 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.74803 to 1.72394, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 32/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.8612 - acc: 0.4405 - val_loss: 1.7152 - val_acc: 0.4931\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.72394 to 1.71524, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 33/400\n",
      "4295/4295 [==============================] - 18s 4ms/step - loss: 1.8250 - acc: 0.4612 - val_loss: 1.6730 - val_acc: 0.5045\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.71524 to 1.67298, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 34/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.8049 - acc: 0.4624 - val_loss: 1.6562 - val_acc: 0.5053\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.67298 to 1.65623, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 35/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.7972 - acc: 0.4594 - val_loss: 1.6603 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.65623\n",
      "Epoch 36/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 1.7868 - acc: 0.4645 - val_loss: 1.6174 - val_acc: 0.5183\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.65623 to 1.61741, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 37/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 1.7178 - acc: 0.4775 - val_loss: 1.6131 - val_acc: 0.5232\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.61741 to 1.61315, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 38/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.7539 - acc: 0.4554 - val_loss: 1.6404 - val_acc: 0.5069\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.61315\n",
      "Epoch 39/400\n",
      "4295/4295 [==============================] - 15s 4ms/step - loss: 1.7257 - acc: 0.4824 - val_loss: 1.5770 - val_acc: 0.5192\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.61315 to 1.57700, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 40/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 1.6961 - acc: 0.4799 - val_loss: 1.5709 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.57700 to 1.57094, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 41/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.7093 - acc: 0.4789 - val_loss: 1.5892 - val_acc: 0.5306\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.57094\n",
      "Epoch 42/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.6881 - acc: 0.4827 - val_loss: 1.5834 - val_acc: 0.5297\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.57094\n",
      "Epoch 43/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.6851 - acc: 0.4845 - val_loss: 1.5718 - val_acc: 0.5175\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.57094\n",
      "Epoch 44/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.6701 - acc: 0.4908 - val_loss: 1.5180 - val_acc: 0.5444\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.57094 to 1.51805, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 45/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.6291 - acc: 0.4948 - val_loss: 1.5273 - val_acc: 0.5232\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.51805\n",
      "Epoch 46/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.5887 - acc: 0.5125 - val_loss: 1.4862 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.51805 to 1.48619, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 47/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.5967 - acc: 0.5073 - val_loss: 1.5095 - val_acc: 0.5322\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.48619\n",
      "Epoch 48/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.5804 - acc: 0.4999 - val_loss: 1.4835 - val_acc: 0.5330\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.48619 to 1.48350, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 49/400\n",
      "4295/4295 [==============================] - 15s 4ms/step - loss: 1.6034 - acc: 0.5006 - val_loss: 1.4584 - val_acc: 0.5550\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.48350 to 1.45835, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 50/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 1.5403 - acc: 0.5185 - val_loss: 1.4491 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.45835 to 1.44909, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 51/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 1.5441 - acc: 0.5311 - val_loss: 1.4452 - val_acc: 0.5509\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.44909 to 1.44518, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 52/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 1.5370 - acc: 0.5176 - val_loss: 1.4199 - val_acc: 0.5599\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.44518 to 1.41990, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 53/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.5130 - acc: 0.5308 - val_loss: 1.4023 - val_acc: 0.5689\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.41990 to 1.40231, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 54/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.5246 - acc: 0.5264 - val_loss: 1.4056 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.40231\n",
      "Epoch 55/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.4999 - acc: 0.5320 - val_loss: 1.4167 - val_acc: 0.5575\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.40231\n",
      "Epoch 56/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.4728 - acc: 0.5458 - val_loss: 1.3723 - val_acc: 0.5729\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.40231 to 1.37226, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 57/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.4765 - acc: 0.5355 - val_loss: 1.3941 - val_acc: 0.5689\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.37226\n",
      "Epoch 58/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.4732 - acc: 0.5430 - val_loss: 1.3762 - val_acc: 0.5721\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.37226\n",
      "Epoch 59/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.4648 - acc: 0.5392 - val_loss: 1.3478 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.37226 to 1.34782, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 60/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.4241 - acc: 0.5544 - val_loss: 1.4484 - val_acc: 0.5615\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.34782\n",
      "Epoch 61/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.4826 - acc: 0.5269 - val_loss: 1.3259 - val_acc: 0.5884\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.34782 to 1.32592, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 62/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.3952 - acc: 0.5648 - val_loss: 1.3338 - val_acc: 0.5827\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.32592\n",
      "Epoch 63/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.4504 - acc: 0.5483 - val_loss: 1.3663 - val_acc: 0.5803\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.32592\n",
      "Epoch 64/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.4096 - acc: 0.5558 - val_loss: 1.3062 - val_acc: 0.5892\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.32592 to 1.30617, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 65/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.3983 - acc: 0.5544 - val_loss: 1.3214 - val_acc: 0.5835\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.30617\n",
      "Epoch 66/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.3905 - acc: 0.5616 - val_loss: 1.3029 - val_acc: 0.5933\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.30617 to 1.30294, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 67/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.3752 - acc: 0.5686 - val_loss: 1.3327 - val_acc: 0.5868\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.30294\n",
      "Epoch 68/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.3893 - acc: 0.5588 - val_loss: 1.3057 - val_acc: 0.6039\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.30294\n",
      "Epoch 69/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3840 - acc: 0.5681 - val_loss: 1.2756 - val_acc: 0.6023\n",
      "\n",
      "Epoch 00069: val_loss improved from 1.30294 to 1.27563, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 70/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3717 - acc: 0.5641 - val_loss: 1.2932 - val_acc: 0.5884\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.27563\n",
      "Epoch 71/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3121 - acc: 0.5858 - val_loss: 1.2521 - val_acc: 0.6129\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.27563 to 1.25212, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 72/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3220 - acc: 0.5795 - val_loss: 1.2500 - val_acc: 0.6104\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.25212 to 1.25001, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 73/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3284 - acc: 0.5800 - val_loss: 1.3038 - val_acc: 0.5754\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.25001\n",
      "Epoch 74/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3124 - acc: 0.5788 - val_loss: 1.2742 - val_acc: 0.5990\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.25001\n",
      "Epoch 75/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3158 - acc: 0.5825 - val_loss: 1.2335 - val_acc: 0.6202\n",
      "\n",
      "Epoch 00075: val_loss improved from 1.25001 to 1.23348, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 76/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3000 - acc: 0.5790 - val_loss: 1.2356 - val_acc: 0.6202\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.23348\n",
      "Epoch 77/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.3049 - acc: 0.5788 - val_loss: 1.2273 - val_acc: 0.6186\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.23348 to 1.22725, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 78/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.3048 - acc: 0.5865 - val_loss: 1.2339 - val_acc: 0.6023\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.22725\n",
      "Epoch 79/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.2512 - acc: 0.6033 - val_loss: 1.2325 - val_acc: 0.6186\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.22725\n",
      "Epoch 80/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.3055 - acc: 0.5893 - val_loss: 1.2303 - val_acc: 0.6186\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.22725\n",
      "Epoch 81/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.2970 - acc: 0.5916 - val_loss: 1.2107 - val_acc: 0.6210\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.22725 to 1.21070, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 82/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.2648 - acc: 0.5977 - val_loss: 1.1985 - val_acc: 0.6218\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.21070 to 1.19847, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 83/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.2556 - acc: 0.5998 - val_loss: 1.2001 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.19847\n",
      "Epoch 84/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.2383 - acc: 0.6091 - val_loss: 1.1849 - val_acc: 0.6259\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.19847 to 1.18491, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 85/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.2316 - acc: 0.6033 - val_loss: 1.1738 - val_acc: 0.6235\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.18491 to 1.17377, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 86/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.2312 - acc: 0.6040 - val_loss: 1.1860 - val_acc: 0.6341\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.17377\n",
      "Epoch 87/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.2312 - acc: 0.6091 - val_loss: 1.1698 - val_acc: 0.6333\n",
      "\n",
      "Epoch 00087: val_loss improved from 1.17377 to 1.16981, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 88/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.2291 - acc: 0.6093 - val_loss: 1.1736 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.16981\n",
      "Epoch 89/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.1934 - acc: 0.6116 - val_loss: 1.2013 - val_acc: 0.6284\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.16981\n",
      "Epoch 90/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.2055 - acc: 0.6105 - val_loss: 1.1495 - val_acc: 0.6365\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.16981 to 1.14950, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 91/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.2026 - acc: 0.6105 - val_loss: 1.1604 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.14950\n",
      "Epoch 92/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.1619 - acc: 0.6263 - val_loss: 1.2337 - val_acc: 0.6178\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.14950\n",
      "Epoch 93/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.2264 - acc: 0.6121 - val_loss: 1.2066 - val_acc: 0.6227\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.14950\n",
      "Epoch 94/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.2154 - acc: 0.6116 - val_loss: 1.1578 - val_acc: 0.6324\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.14950\n",
      "Epoch 95/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.1773 - acc: 0.6200 - val_loss: 1.1570 - val_acc: 0.6227\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.14950\n",
      "Epoch 96/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.1905 - acc: 0.6135 - val_loss: 1.1614 - val_acc: 0.6365\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.14950\n",
      "Epoch 97/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.1770 - acc: 0.6168 - val_loss: 1.2407 - val_acc: 0.6202\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.14950\n",
      "Epoch 98/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.1725 - acc: 0.6244 - val_loss: 1.1440 - val_acc: 0.6544\n",
      "\n",
      "Epoch 00098: val_loss improved from 1.14950 to 1.14396, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 99/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 1.1562 - acc: 0.6265 - val_loss: 1.1434 - val_acc: 0.6463\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.14396 to 1.14338, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 100/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295/4295 [==============================] - 15s 4ms/step - loss: 1.1662 - acc: 0.6226 - val_loss: 1.1180 - val_acc: 0.6569\n",
      "\n",
      "Epoch 00100: val_loss improved from 1.14338 to 1.11799, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 101/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 1.1364 - acc: 0.6368 - val_loss: 1.0936 - val_acc: 0.6601\n",
      "\n",
      "Epoch 00101: val_loss improved from 1.11799 to 1.09359, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 102/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 1.1218 - acc: 0.6356 - val_loss: 1.1302 - val_acc: 0.6414\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.09359\n",
      "Epoch 103/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.1633 - acc: 0.6307 - val_loss: 1.1379 - val_acc: 0.6414\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.09359\n",
      "Epoch 104/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.1432 - acc: 0.6345 - val_loss: 1.1537 - val_acc: 0.6373\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.09359\n",
      "Epoch 105/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.1303 - acc: 0.6324 - val_loss: 1.1216 - val_acc: 0.6504\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.09359\n",
      "Epoch 106/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.1350 - acc: 0.6324 - val_loss: 1.1073 - val_acc: 0.6520\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.09359\n",
      "Epoch 107/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.1206 - acc: 0.6319 - val_loss: 1.1192 - val_acc: 0.6536\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.09359\n",
      "Epoch 108/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.1135 - acc: 0.6356 - val_loss: 1.1400 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.09359\n",
      "Epoch 109/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0927 - acc: 0.6435 - val_loss: 1.0970 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.09359\n",
      "Epoch 110/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.1259 - acc: 0.6391 - val_loss: 1.0894 - val_acc: 0.6675\n",
      "\n",
      "Epoch 00110: val_loss improved from 1.09359 to 1.08937, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 111/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0814 - acc: 0.6384 - val_loss: 1.0785 - val_acc: 0.6520\n",
      "\n",
      "Epoch 00111: val_loss improved from 1.08937 to 1.07851, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 112/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0980 - acc: 0.6431 - val_loss: 1.0583 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00112: val_loss improved from 1.07851 to 1.05835, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 113/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0966 - acc: 0.6442 - val_loss: 1.0581 - val_acc: 0.6764\n",
      "\n",
      "Epoch 00113: val_loss improved from 1.05835 to 1.05813, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 114/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0970 - acc: 0.6496 - val_loss: 1.0844 - val_acc: 0.6675\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.05813\n",
      "Epoch 115/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0790 - acc: 0.6433 - val_loss: 1.0683 - val_acc: 0.6675\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.05813\n",
      "Epoch 116/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0730 - acc: 0.6568 - val_loss: 1.0862 - val_acc: 0.6610\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.05813\n",
      "Epoch 117/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0685 - acc: 0.6522 - val_loss: 1.0893 - val_acc: 0.6463\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.05813\n",
      "Epoch 118/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0476 - acc: 0.6580 - val_loss: 1.0891 - val_acc: 0.6618\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.05813\n",
      "Epoch 119/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0730 - acc: 0.6498 - val_loss: 1.0719 - val_acc: 0.6642\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.05813\n",
      "Epoch 120/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0314 - acc: 0.6694 - val_loss: 1.0700 - val_acc: 0.6601\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.05813\n",
      "Epoch 121/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0804 - acc: 0.6559 - val_loss: 1.0982 - val_acc: 0.6479\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.05813\n",
      "Epoch 122/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0325 - acc: 0.6689 - val_loss: 1.0572 - val_acc: 0.6724\n",
      "\n",
      "Epoch 00122: val_loss improved from 1.05813 to 1.05721, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 123/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0569 - acc: 0.6526 - val_loss: 1.0770 - val_acc: 0.6756\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.05721\n",
      "Epoch 124/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0135 - acc: 0.6754 - val_loss: 1.0867 - val_acc: 0.6642\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.05721\n",
      "Epoch 125/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 1.0271 - acc: 0.6671 - val_loss: 1.0378 - val_acc: 0.6707\n",
      "\n",
      "Epoch 00125: val_loss improved from 1.05721 to 1.03779, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 126/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0748 - acc: 0.6547 - val_loss: 1.0468 - val_acc: 0.6764\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.03779\n",
      "Epoch 127/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0295 - acc: 0.6626 - val_loss: 1.0564 - val_acc: 0.6748\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.03779\n",
      "Epoch 128/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0624 - acc: 0.6512 - val_loss: 1.0449 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.03779\n",
      "Epoch 129/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0193 - acc: 0.6680 - val_loss: 1.0743 - val_acc: 0.6593\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.03779\n",
      "Epoch 130/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0496 - acc: 0.6538 - val_loss: 1.0471 - val_acc: 0.6699\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.03779\n",
      "Epoch 131/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9898 - acc: 0.6696 - val_loss: 1.0276 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00131: val_loss improved from 1.03779 to 1.02757, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 132/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 1.0075 - acc: 0.6689 - val_loss: 1.0226 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00132: val_loss improved from 1.02757 to 1.02262, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 133/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9858 - acc: 0.6745 - val_loss: 1.0339 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.02262\n",
      "Epoch 134/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9939 - acc: 0.6740 - val_loss: 1.0241 - val_acc: 0.6862\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.02262\n",
      "Epoch 135/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9946 - acc: 0.6801 - val_loss: 1.0870 - val_acc: 0.6536\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.02262\n",
      "Epoch 136/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9851 - acc: 0.6752 - val_loss: 1.0165 - val_acc: 0.6773\n",
      "\n",
      "Epoch 00136: val_loss improved from 1.02262 to 1.01647, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 137/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9837 - acc: 0.6752 - val_loss: 1.0303 - val_acc: 0.6740\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.01647\n",
      "Epoch 138/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9736 - acc: 0.6813 - val_loss: 1.0398 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.01647\n",
      "Epoch 139/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.9760 - acc: 0.6768 - val_loss: 0.9979 - val_acc: 0.6822\n",
      "\n",
      "Epoch 00139: val_loss improved from 1.01647 to 0.99791, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 140/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9921 - acc: 0.6666 - val_loss: 1.0526 - val_acc: 0.6683\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.99791\n",
      "Epoch 141/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9764 - acc: 0.6892 - val_loss: 1.0027 - val_acc: 0.6862\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.99791\n",
      "Epoch 142/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9731 - acc: 0.6852 - val_loss: 0.9924 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.99791 to 0.99238, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 143/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9765 - acc: 0.6936 - val_loss: 0.9946 - val_acc: 0.6895\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.99238\n",
      "Epoch 144/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9538 - acc: 0.6838 - val_loss: 1.0373 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.99238\n",
      "Epoch 145/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9419 - acc: 0.6952 - val_loss: 0.9765 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.99238 to 0.97648, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 146/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9675 - acc: 0.6873 - val_loss: 0.9830 - val_acc: 0.6919\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.97648\n",
      "Epoch 147/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9362 - acc: 0.6913 - val_loss: 1.0472 - val_acc: 0.6707\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.97648\n",
      "Epoch 148/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9142 - acc: 0.6943 - val_loss: 1.0012 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.97648\n",
      "Epoch 149/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9225 - acc: 0.6908 - val_loss: 0.9844 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.97648\n",
      "Epoch 150/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9697 - acc: 0.6824 - val_loss: 1.0050 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.97648\n",
      "Epoch 151/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9644 - acc: 0.6799 - val_loss: 1.0301 - val_acc: 0.6879\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.97648\n",
      "Epoch 152/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9210 - acc: 0.7057 - val_loss: 0.9854 - val_acc: 0.6838\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.97648\n",
      "Epoch 153/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9146 - acc: 0.7020 - val_loss: 1.0551 - val_acc: 0.6618\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.97648\n",
      "Epoch 154/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9395 - acc: 0.6920 - val_loss: 1.0141 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.97648\n",
      "Epoch 155/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9175 - acc: 0.6997 - val_loss: 0.9841 - val_acc: 0.6887\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.97648\n",
      "Epoch 156/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8988 - acc: 0.7020 - val_loss: 1.0117 - val_acc: 0.6642\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.97648\n",
      "Epoch 157/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9313 - acc: 0.6962 - val_loss: 0.9834 - val_acc: 0.6919\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.97648\n",
      "Epoch 158/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9082 - acc: 0.7057 - val_loss: 0.9820 - val_acc: 0.6944\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.97648\n",
      "Epoch 159/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9124 - acc: 0.7066 - val_loss: 0.9652 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.97648 to 0.96525, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 160/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9105 - acc: 0.6969 - val_loss: 0.9724 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.96525\n",
      "Epoch 161/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9001 - acc: 0.6985 - val_loss: 0.9463 - val_acc: 0.7058\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.96525 to 0.94628, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 162/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9000 - acc: 0.7057 - val_loss: 0.9802 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.94628\n",
      "Epoch 163/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8923 - acc: 0.7034 - val_loss: 0.9704 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.94628\n",
      "Epoch 164/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9275 - acc: 0.6966 - val_loss: 0.9861 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.94628\n",
      "Epoch 165/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.9193 - acc: 0.6950 - val_loss: 0.9848 - val_acc: 0.6887\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.94628\n",
      "Epoch 166/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9130 - acc: 0.7024 - val_loss: 0.9965 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.94628\n",
      "Epoch 167/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8737 - acc: 0.7055 - val_loss: 0.9666 - val_acc: 0.7033\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.94628\n",
      "Epoch 168/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8623 - acc: 0.7115 - val_loss: 0.9602 - val_acc: 0.7025\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.94628\n",
      "Epoch 169/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8483 - acc: 0.7159 - val_loss: 0.9492 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.94628\n",
      "Epoch 170/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.9259 - acc: 0.6994 - val_loss: 0.9488 - val_acc: 0.7033\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.94628\n",
      "Epoch 171/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8848 - acc: 0.7041 - val_loss: 0.9471 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.94628\n",
      "Epoch 172/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8375 - acc: 0.7248 - val_loss: 0.9357 - val_acc: 0.7017\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.94628 to 0.93569, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 173/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8500 - acc: 0.7166 - val_loss: 0.9592 - val_acc: 0.7033\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.93569\n",
      "Epoch 174/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8766 - acc: 0.7125 - val_loss: 1.1020 - val_acc: 0.6455\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.93569\n",
      "Epoch 175/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8667 - acc: 0.7153 - val_loss: 0.9637 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.93569\n",
      "Epoch 176/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8422 - acc: 0.7150 - val_loss: 0.9492 - val_acc: 0.6976\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.93569\n",
      "Epoch 177/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8543 - acc: 0.7192 - val_loss: 0.9724 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.93569\n",
      "Epoch 178/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8751 - acc: 0.7083 - val_loss: 0.9328 - val_acc: 0.7066\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.93569 to 0.93280, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 179/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8488 - acc: 0.7183 - val_loss: 0.9330 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.93280\n",
      "Epoch 180/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8392 - acc: 0.7199 - val_loss: 0.9196 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.93280 to 0.91958, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 181/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8328 - acc: 0.7271 - val_loss: 0.9235 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.91958\n",
      "Epoch 182/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8426 - acc: 0.7241 - val_loss: 0.9673 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.91958\n",
      "Epoch 183/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8693 - acc: 0.7122 - val_loss: 0.9195 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.91958 to 0.91949, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 184/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8202 - acc: 0.7329 - val_loss: 0.9057 - val_acc: 0.7131\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.91949 to 0.90570, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 185/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8542 - acc: 0.7150 - val_loss: 0.9895 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.90570\n",
      "Epoch 186/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8304 - acc: 0.7225 - val_loss: 0.9803 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.90570\n",
      "Epoch 187/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8488 - acc: 0.7201 - val_loss: 0.9697 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.90570\n",
      "Epoch 188/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8217 - acc: 0.7150 - val_loss: 0.9446 - val_acc: 0.7017\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.90570\n",
      "Epoch 189/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8235 - acc: 0.7255 - val_loss: 0.9532 - val_acc: 0.7001\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.90570\n",
      "Epoch 190/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8295 - acc: 0.7239 - val_loss: 0.9401 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.90570\n",
      "Epoch 191/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8302 - acc: 0.7199 - val_loss: 0.9863 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.90570\n",
      "Epoch 192/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8401 - acc: 0.7197 - val_loss: 0.9417 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.90570\n",
      "Epoch 193/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8064 - acc: 0.7320 - val_loss: 0.9317 - val_acc: 0.7074\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.90570\n",
      "Epoch 194/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8022 - acc: 0.7385 - val_loss: 1.0098 - val_acc: 0.6919\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.90570\n",
      "Epoch 195/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8805 - acc: 0.7122 - val_loss: 0.9338 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.90570\n",
      "Epoch 196/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8153 - acc: 0.7369 - val_loss: 0.9164 - val_acc: 0.7074\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.90570\n",
      "Epoch 197/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8247 - acc: 0.7187 - val_loss: 0.9144 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.90570\n",
      "Epoch 198/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.8349 - acc: 0.7288 - val_loss: 0.9495 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.90570\n",
      "Epoch 199/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.8118 - acc: 0.7278 - val_loss: 0.9166 - val_acc: 0.7074\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.90570\n",
      "Epoch 200/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7973 - acc: 0.7320 - val_loss: 0.9388 - val_acc: 0.7001\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.90570\n",
      "Epoch 201/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7864 - acc: 0.7378 - val_loss: 0.8956 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.90570 to 0.89564, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 202/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7866 - acc: 0.7392 - val_loss: 0.9167 - val_acc: 0.7107\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.89564\n",
      "Epoch 203/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8040 - acc: 0.7329 - val_loss: 0.9182 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.89564\n",
      "Epoch 204/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7964 - acc: 0.7302 - val_loss: 0.9169 - val_acc: 0.7066\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.89564\n",
      "Epoch 205/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8036 - acc: 0.7292 - val_loss: 0.9213 - val_acc: 0.7115\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.89564\n",
      "Epoch 206/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7991 - acc: 0.7374 - val_loss: 0.9171 - val_acc: 0.7066\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.89564\n",
      "Epoch 207/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.8087 - acc: 0.7267 - val_loss: 0.8967 - val_acc: 0.7099\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.89564\n",
      "Epoch 208/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7986 - acc: 0.7329 - val_loss: 0.8950 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.89564 to 0.89500, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 209/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7847 - acc: 0.7339 - val_loss: 0.9283 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.89500\n",
      "Epoch 210/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7601 - acc: 0.7451 - val_loss: 0.9547 - val_acc: 0.7001\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.89500\n",
      "Epoch 211/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7868 - acc: 0.7395 - val_loss: 0.9185 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.89500\n",
      "Epoch 212/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7936 - acc: 0.7362 - val_loss: 0.9084 - val_acc: 0.7131\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.89500\n",
      "Epoch 213/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7816 - acc: 0.7411 - val_loss: 0.8970 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.89500\n",
      "Epoch 214/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8048 - acc: 0.7295 - val_loss: 0.9083 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.89500\n",
      "Epoch 215/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8051 - acc: 0.7290 - val_loss: 0.9264 - val_acc: 0.7148\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.89500\n",
      "Epoch 216/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7759 - acc: 0.7355 - val_loss: 0.8971 - val_acc: 0.7107\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.89500\n",
      "Epoch 217/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7693 - acc: 0.7350 - val_loss: 0.9224 - val_acc: 0.6968\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.89500\n",
      "Epoch 218/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.8156 - acc: 0.7201 - val_loss: 0.9322 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.89500\n",
      "Epoch 219/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7821 - acc: 0.7367 - val_loss: 0.8926 - val_acc: 0.7213\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.89500 to 0.89263, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 220/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7562 - acc: 0.7467 - val_loss: 0.9066 - val_acc: 0.7245\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.89263\n",
      "Epoch 221/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7904 - acc: 0.7376 - val_loss: 0.9030 - val_acc: 0.7286\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.89263\n",
      "Epoch 222/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7652 - acc: 0.7451 - val_loss: 0.8875 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.89263 to 0.88746, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 223/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7440 - acc: 0.7506 - val_loss: 0.8863 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.88746 to 0.88633, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 224/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7582 - acc: 0.7485 - val_loss: 0.9024 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.88633\n",
      "Epoch 225/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7666 - acc: 0.7416 - val_loss: 0.8927 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.88633\n",
      "Epoch 226/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7554 - acc: 0.7464 - val_loss: 0.8830 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.88633 to 0.88301, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 227/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 0.7558 - acc: 0.7390 - val_loss: 0.9450 - val_acc: 0.7107\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.88301\n",
      "Epoch 228/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7472 - acc: 0.7453 - val_loss: 0.8863 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.88301\n",
      "Epoch 229/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7233 - acc: 0.7600 - val_loss: 0.9264 - val_acc: 0.7066\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.88301\n",
      "Epoch 230/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7427 - acc: 0.7488 - val_loss: 0.8843 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.88301\n",
      "Epoch 231/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7217 - acc: 0.7581 - val_loss: 0.9307 - val_acc: 0.7058\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.88301\n",
      "Epoch 232/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7575 - acc: 0.7520 - val_loss: 0.8944 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.88301\n",
      "Epoch 233/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7337 - acc: 0.7518 - val_loss: 0.8875 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.88301\n",
      "Epoch 234/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7270 - acc: 0.7481 - val_loss: 0.9010 - val_acc: 0.7058\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.88301\n",
      "Epoch 235/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7733 - acc: 0.7397 - val_loss: 0.8937 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.88301\n",
      "Epoch 236/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7332 - acc: 0.7562 - val_loss: 0.8829 - val_acc: 0.7237\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.88301 to 0.88287, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 237/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7270 - acc: 0.7611 - val_loss: 0.8778 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.88287 to 0.87783, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 238/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7439 - acc: 0.7541 - val_loss: 0.8832 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.87783\n",
      "Epoch 239/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7454 - acc: 0.7481 - val_loss: 0.8801 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.87783\n",
      "Epoch 240/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7283 - acc: 0.7600 - val_loss: 0.8927 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.87783\n",
      "Epoch 241/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7202 - acc: 0.7595 - val_loss: 0.8587 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.87783 to 0.85870, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 242/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7163 - acc: 0.7590 - val_loss: 0.9155 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.85870\n",
      "Epoch 243/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7327 - acc: 0.7511 - val_loss: 0.9264 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.85870\n",
      "Epoch 244/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7443 - acc: 0.7471 - val_loss: 0.8625 - val_acc: 0.7286\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.85870\n",
      "Epoch 245/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7164 - acc: 0.7544 - val_loss: 0.8881 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.85870\n",
      "Epoch 246/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6983 - acc: 0.7690 - val_loss: 0.9009 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.85870\n",
      "Epoch 247/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7132 - acc: 0.7616 - val_loss: 0.8833 - val_acc: 0.7221\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.85870\n",
      "Epoch 248/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7031 - acc: 0.7597 - val_loss: 0.9280 - val_acc: 0.7017\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.85870\n",
      "Epoch 249/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7322 - acc: 0.7597 - val_loss: 0.8951 - val_acc: 0.7221\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.85870\n",
      "Epoch 250/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7135 - acc: 0.7502 - val_loss: 0.9026 - val_acc: 0.7099\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.85870\n",
      "Epoch 251/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7395 - acc: 0.7569 - val_loss: 0.8987 - val_acc: 0.7213\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.85870\n",
      "Epoch 252/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7358 - acc: 0.7558 - val_loss: 0.9440 - val_acc: 0.7017\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.85870\n",
      "Epoch 253/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7630 - acc: 0.7423 - val_loss: 0.8916 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.85870\n",
      "Epoch 254/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6830 - acc: 0.7697 - val_loss: 0.8595 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.85870\n",
      "Epoch 255/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7304 - acc: 0.7639 - val_loss: 0.8627 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.85870\n",
      "Epoch 256/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6966 - acc: 0.7655 - val_loss: 0.8530 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.85870 to 0.85301, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 257/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6982 - acc: 0.7618 - val_loss: 0.8938 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.85301\n",
      "Epoch 258/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7140 - acc: 0.7644 - val_loss: 0.8809 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.85301\n",
      "Epoch 259/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7234 - acc: 0.7588 - val_loss: 0.8746 - val_acc: 0.7245\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.85301\n",
      "Epoch 260/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7475 - acc: 0.7532 - val_loss: 0.8718 - val_acc: 0.7368\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.85301\n",
      "Epoch 261/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6966 - acc: 0.7681 - val_loss: 0.8788 - val_acc: 0.7311\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.85301\n",
      "Epoch 262/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7042 - acc: 0.7625 - val_loss: 0.8603 - val_acc: 0.7286\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.85301\n",
      "Epoch 263/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7099 - acc: 0.7567 - val_loss: 0.9027 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.85301\n",
      "Epoch 264/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7177 - acc: 0.7597 - val_loss: 0.8608 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.85301\n",
      "Epoch 265/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6910 - acc: 0.7639 - val_loss: 0.8527 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.85301 to 0.85268, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 266/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6744 - acc: 0.7767 - val_loss: 0.8625 - val_acc: 0.7294\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.85268\n",
      "Epoch 267/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6977 - acc: 0.7700 - val_loss: 0.8508 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.85268 to 0.85077, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 268/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6875 - acc: 0.7665 - val_loss: 0.8550 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.85077\n",
      "Epoch 269/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6833 - acc: 0.7630 - val_loss: 0.8710 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.85077\n",
      "Epoch 270/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6602 - acc: 0.7795 - val_loss: 0.9651 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.85077\n",
      "Epoch 271/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7368 - acc: 0.7544 - val_loss: 0.8434 - val_acc: 0.7311\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.85077 to 0.84345, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 272/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6540 - acc: 0.7823 - val_loss: 0.8340 - val_acc: 0.7384\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.84345 to 0.83403, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 273/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.6721 - acc: 0.7716 - val_loss: 0.8998 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.83403\n",
      "Epoch 274/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 0.7333 - acc: 0.7609 - val_loss: 1.0285 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.83403\n",
      "Epoch 275/400\n",
      "4295/4295 [==============================] - 15s 4ms/step - loss: 0.6721 - acc: 0.7714 - val_loss: 0.8563 - val_acc: 0.7343\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.83403\n",
      "Epoch 276/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 0.6509 - acc: 0.7781 - val_loss: 0.8639 - val_acc: 0.7294\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.83403\n",
      "Epoch 277/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 0.6776 - acc: 0.7709 - val_loss: 0.9117 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.83403\n",
      "Epoch 278/400\n",
      "4295/4295 [==============================] - 18s 4ms/step - loss: 0.6970 - acc: 0.7637 - val_loss: 0.8439 - val_acc: 0.7351\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.83403\n",
      "Epoch 279/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 0.7205 - acc: 0.7595 - val_loss: 0.8603 - val_acc: 0.7359\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.83403\n",
      "Epoch 280/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 0.6536 - acc: 0.7793 - val_loss: 0.8626 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.83403\n",
      "Epoch 281/400\n",
      "4295/4295 [==============================] - 19s 4ms/step - loss: 0.6597 - acc: 0.7769 - val_loss: 0.8503 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.83403\n",
      "Epoch 282/400\n",
      "4295/4295 [==============================] - 19s 4ms/step - loss: 0.6704 - acc: 0.7704 - val_loss: 0.8675 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.83403\n",
      "Epoch 283/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 0.6618 - acc: 0.7746 - val_loss: 0.8520 - val_acc: 0.7335\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.83403\n",
      "Epoch 284/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.6386 - acc: 0.7832 - val_loss: 0.8254 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.83403 to 0.82540, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 285/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6759 - acc: 0.7697 - val_loss: 0.8213 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.82540 to 0.82131, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 286/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6446 - acc: 0.7851 - val_loss: 0.8482 - val_acc: 0.7343\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.82131\n",
      "Epoch 287/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6677 - acc: 0.7697 - val_loss: 0.8689 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.82131\n",
      "Epoch 288/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6292 - acc: 0.7905 - val_loss: 0.8358 - val_acc: 0.7335\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.82131\n",
      "Epoch 289/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6652 - acc: 0.7767 - val_loss: 0.8639 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.82131\n",
      "Epoch 290/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6713 - acc: 0.7732 - val_loss: 0.8447 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.82131\n",
      "Epoch 291/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.7064 - acc: 0.7641 - val_loss: 0.8516 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.82131\n",
      "Epoch 292/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.6666 - acc: 0.7667 - val_loss: 0.9263 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.82131\n",
      "Epoch 293/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.6713 - acc: 0.7735 - val_loss: 0.8649 - val_acc: 0.7335\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.82131\n",
      "Epoch 294/400\n",
      "4295/4295 [==============================] - 15s 4ms/step - loss: 0.6672 - acc: 0.7804 - val_loss: 0.8520 - val_acc: 0.7294\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.82131\n",
      "Epoch 295/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.6411 - acc: 0.7811 - val_loss: 0.9048 - val_acc: 0.7213\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.82131\n",
      "Epoch 296/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.7253 - acc: 0.7541 - val_loss: 0.8789 - val_acc: 0.7245\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.82131\n",
      "Epoch 297/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6683 - acc: 0.7823 - val_loss: 0.8368 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.82131\n",
      "Epoch 298/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6517 - acc: 0.7809 - val_loss: 0.9017 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.82131\n",
      "Epoch 299/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6515 - acc: 0.7837 - val_loss: 0.8364 - val_acc: 0.7359\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.82131\n",
      "Epoch 300/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6277 - acc: 0.7844 - val_loss: 0.8241 - val_acc: 0.7376\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.82131\n",
      "Epoch 301/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6303 - acc: 0.7958 - val_loss: 0.8218 - val_acc: 0.7392\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.82131\n",
      "Epoch 302/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6013 - acc: 0.7986 - val_loss: 0.8365 - val_acc: 0.7335\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.82131\n",
      "Epoch 303/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6746 - acc: 0.7746 - val_loss: 0.8334 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.82131\n",
      "Epoch 304/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6529 - acc: 0.7804 - val_loss: 0.8267 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.82131\n",
      "Epoch 305/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6373 - acc: 0.7870 - val_loss: 0.8322 - val_acc: 0.7359\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.82131\n",
      "Epoch 306/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6374 - acc: 0.7888 - val_loss: 0.8129 - val_acc: 0.7359\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.82131 to 0.81289, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 307/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6539 - acc: 0.7835 - val_loss: 0.8198 - val_acc: 0.7465\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.81289\n",
      "Epoch 308/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6588 - acc: 0.7856 - val_loss: 0.8228 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.81289\n",
      "Epoch 309/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6300 - acc: 0.7825 - val_loss: 0.8223 - val_acc: 0.7433\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.81289\n",
      "Epoch 310/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.6326 - acc: 0.7853 - val_loss: 0.8257 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.81289\n",
      "Epoch 311/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6536 - acc: 0.7783 - val_loss: 0.9017 - val_acc: 0.7237\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.81289\n",
      "Epoch 312/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6491 - acc: 0.7809 - val_loss: 0.8318 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.81289\n",
      "Epoch 313/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6760 - acc: 0.7758 - val_loss: 0.8493 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.81289\n",
      "Epoch 314/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6319 - acc: 0.7823 - val_loss: 0.8043 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.81289 to 0.80433, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 315/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6219 - acc: 0.7930 - val_loss: 0.8238 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.80433\n",
      "Epoch 316/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6367 - acc: 0.7874 - val_loss: 0.8263 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.80433\n",
      "Epoch 317/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6662 - acc: 0.7688 - val_loss: 0.8613 - val_acc: 0.7335\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.80433\n",
      "Epoch 318/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6124 - acc: 0.8035 - val_loss: 0.8182 - val_acc: 0.7359\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.80433\n",
      "Epoch 319/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6310 - acc: 0.7888 - val_loss: 0.8474 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.80433\n",
      "Epoch 320/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6129 - acc: 0.7821 - val_loss: 0.8175 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.80433\n",
      "Epoch 321/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6205 - acc: 0.7846 - val_loss: 0.8194 - val_acc: 0.7416\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.80433\n",
      "Epoch 322/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5944 - acc: 0.7939 - val_loss: 0.8183 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.80433\n",
      "Epoch 323/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6009 - acc: 0.7988 - val_loss: 0.8546 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.80433\n",
      "Epoch 324/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6516 - acc: 0.7821 - val_loss: 0.8272 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.80433\n",
      "Epoch 325/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6063 - acc: 0.7942 - val_loss: 0.8448 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.80433\n",
      "Epoch 326/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6487 - acc: 0.7804 - val_loss: 0.8472 - val_acc: 0.7351\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.80433\n",
      "Epoch 327/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6167 - acc: 0.7898 - val_loss: 0.8214 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.80433\n",
      "Epoch 328/400\n",
      "4295/4295 [==============================] - 15s 4ms/step - loss: 0.5862 - acc: 0.7979 - val_loss: 0.8429 - val_acc: 0.7433\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.80433\n",
      "Epoch 329/400\n",
      "4295/4295 [==============================] - 18s 4ms/step - loss: 0.6114 - acc: 0.7988 - val_loss: 0.9057 - val_acc: 0.7213\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.80433\n",
      "Epoch 330/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 0.6186 - acc: 0.7902 - val_loss: 0.8463 - val_acc: 0.7359\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.80433\n",
      "Epoch 331/400\n",
      "4295/4295 [==============================] - 15s 4ms/step - loss: 0.6228 - acc: 0.7860 - val_loss: 0.8928 - val_acc: 0.7286\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.80433\n",
      "Epoch 332/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 0.6146 - acc: 0.7916 - val_loss: 0.8090 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.80433\n",
      "Epoch 333/400\n",
      "4295/4295 [==============================] - 20s 5ms/step - loss: 0.5928 - acc: 0.7993 - val_loss: 0.8153 - val_acc: 0.7376\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.80433\n",
      "Epoch 334/400\n",
      "4295/4295 [==============================] - 19s 5ms/step - loss: 0.5800 - acc: 0.7981 - val_loss: 0.8217 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.80433\n",
      "Epoch 335/400\n",
      "4295/4295 [==============================] - 16s 4ms/step - loss: 0.5924 - acc: 0.8012 - val_loss: 0.8278 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.80433\n",
      "Epoch 336/400\n",
      "4295/4295 [==============================] - 18s 4ms/step - loss: 0.5870 - acc: 0.8072 - val_loss: 0.8354 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.80433\n",
      "Epoch 337/400\n",
      "4295/4295 [==============================] - 15s 4ms/step - loss: 0.5972 - acc: 0.7923 - val_loss: 0.8352 - val_acc: 0.7392\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.80433\n",
      "Epoch 338/400\n",
      "4295/4295 [==============================] - 17s 4ms/step - loss: 0.6037 - acc: 0.7939 - val_loss: 0.8350 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.80433\n",
      "Epoch 339/400\n",
      "4295/4295 [==============================] - 15s 3ms/step - loss: 0.6289 - acc: 0.7939 - val_loss: 0.8092 - val_acc: 0.7433\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.80433\n",
      "Epoch 340/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6056 - acc: 0.7921 - val_loss: 0.8420 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.80433\n",
      "Epoch 341/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.6109 - acc: 0.8007 - val_loss: 0.8014 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.80433 to 0.80139, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 342/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6075 - acc: 0.7900 - val_loss: 0.8398 - val_acc: 0.7376\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.80139\n",
      "Epoch 343/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6170 - acc: 0.7909 - val_loss: 0.8057 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.80139\n",
      "Epoch 344/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5943 - acc: 0.8014 - val_loss: 0.8211 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.80139\n",
      "Epoch 345/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6055 - acc: 0.8005 - val_loss: 0.8491 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.80139\n",
      "Epoch 346/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5752 - acc: 0.8035 - val_loss: 0.8074 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.80139\n",
      "Epoch 347/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6193 - acc: 0.7881 - val_loss: 0.7999 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.80139 to 0.79986, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 348/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6062 - acc: 0.7925 - val_loss: 0.8594 - val_acc: 0.7311\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.79986\n",
      "Epoch 349/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5984 - acc: 0.7865 - val_loss: 0.8294 - val_acc: 0.7433\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.79986\n",
      "Epoch 350/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6184 - acc: 0.7865 - val_loss: 0.8159 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.79986\n",
      "Epoch 351/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6131 - acc: 0.8026 - val_loss: 1.0376 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.79986\n",
      "Epoch 352/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6207 - acc: 0.7912 - val_loss: 0.8113 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.79986\n",
      "Epoch 353/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5879 - acc: 0.7986 - val_loss: 0.7922 - val_acc: 0.7506\n",
      "\n",
      "Epoch 00353: val_loss improved from 0.79986 to 0.79224, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 354/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5984 - acc: 0.8023 - val_loss: 0.8212 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.79224\n",
      "Epoch 355/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6159 - acc: 0.7860 - val_loss: 0.8230 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.79224\n",
      "Epoch 356/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5578 - acc: 0.8081 - val_loss: 0.8034 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.79224\n",
      "Epoch 357/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5958 - acc: 0.7960 - val_loss: 0.8145 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.79224\n",
      "Epoch 358/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5716 - acc: 0.8051 - val_loss: 0.8816 - val_acc: 0.7384\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.79224\n",
      "Epoch 359/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5793 - acc: 0.8014 - val_loss: 0.8440 - val_acc: 0.7294\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.79224\n",
      "Epoch 360/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5874 - acc: 0.7963 - val_loss: 0.8081 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.79224\n",
      "Epoch 361/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5939 - acc: 0.8012 - val_loss: 0.8491 - val_acc: 0.7351\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.79224\n",
      "Epoch 362/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5779 - acc: 0.8042 - val_loss: 0.8233 - val_acc: 0.7563\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.79224\n",
      "Epoch 363/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5829 - acc: 0.8021 - val_loss: 0.7863 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.79224 to 0.78629, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 364/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5667 - acc: 0.8119 - val_loss: 0.7832 - val_acc: 0.7588\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.78629 to 0.78318, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 365/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5979 - acc: 0.7988 - val_loss: 1.0253 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.78318\n",
      "Epoch 366/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6048 - acc: 0.7965 - val_loss: 0.7850 - val_acc: 0.7555\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.78318\n",
      "Epoch 367/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5541 - acc: 0.8177 - val_loss: 0.8016 - val_acc: 0.7482\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.78318\n",
      "Epoch 368/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6067 - acc: 0.8005 - val_loss: 0.7942 - val_acc: 0.7506\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.78318\n",
      "Epoch 369/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6197 - acc: 0.7874 - val_loss: 0.8248 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.78318\n",
      "Epoch 370/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5757 - acc: 0.8072 - val_loss: 0.8141 - val_acc: 0.7514\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.78318\n",
      "Epoch 371/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5904 - acc: 0.8042 - val_loss: 0.7889 - val_acc: 0.7539\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.78318\n",
      "Epoch 372/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5903 - acc: 0.8042 - val_loss: 0.8395 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.78318\n",
      "Epoch 373/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5770 - acc: 0.8058 - val_loss: 0.8041 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.78318\n",
      "Epoch 374/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5949 - acc: 0.8040 - val_loss: 0.8284 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.78318\n",
      "Epoch 375/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6045 - acc: 0.7956 - val_loss: 0.8271 - val_acc: 0.7433\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.78318\n",
      "Epoch 376/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5888 - acc: 0.7963 - val_loss: 0.8144 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.78318\n",
      "Epoch 377/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5625 - acc: 0.8079 - val_loss: 0.8486 - val_acc: 0.7433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00377: val_loss did not improve from 0.78318\n",
      "Epoch 378/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6043 - acc: 0.7981 - val_loss: 0.8186 - val_acc: 0.7514\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.78318\n",
      "Epoch 379/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5717 - acc: 0.8095 - val_loss: 0.7864 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.78318\n",
      "Epoch 380/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5770 - acc: 0.7998 - val_loss: 0.8401 - val_acc: 0.7343\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.78318\n",
      "Epoch 381/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5783 - acc: 0.8065 - val_loss: 0.8055 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.78318\n",
      "Epoch 382/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5840 - acc: 0.7979 - val_loss: 0.8329 - val_acc: 0.7368\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.78318\n",
      "Epoch 383/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5758 - acc: 0.8133 - val_loss: 0.8132 - val_acc: 0.7563\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.78318\n",
      "Epoch 384/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5519 - acc: 0.8112 - val_loss: 0.8070 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.78318\n",
      "Epoch 385/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5628 - acc: 0.8068 - val_loss: 0.7986 - val_acc: 0.7571\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.78318\n",
      "Epoch 386/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5543 - acc: 0.8051 - val_loss: 0.7870 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.78318\n",
      "Epoch 387/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5611 - acc: 0.8107 - val_loss: 0.8117 - val_acc: 0.7482\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.78318\n",
      "Epoch 388/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5449 - acc: 0.8147 - val_loss: 0.8008 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.78318\n",
      "Epoch 389/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5846 - acc: 0.7944 - val_loss: 0.8037 - val_acc: 0.7531\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.78318\n",
      "Epoch 390/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5680 - acc: 0.8000 - val_loss: 0.7812 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00390: val_loss improved from 0.78318 to 0.78123, saving model to /home/elena/eStep/XAI/Data/LeafSnap/leafsnap-dataset-30subset/Models/leafnet.h5\n",
      "Epoch 391/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5659 - acc: 0.8116 - val_loss: 0.9318 - val_acc: 0.7253\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.78123\n",
      "Epoch 392/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.6523 - acc: 0.7795 - val_loss: 0.7949 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.78123\n",
      "Epoch 393/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5778 - acc: 0.8035 - val_loss: 0.7890 - val_acc: 0.7555\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.78123\n",
      "Epoch 394/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5532 - acc: 0.8068 - val_loss: 0.7854 - val_acc: 0.7637\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.78123\n",
      "Epoch 395/400\n",
      "4295/4295 [==============================] - 14s 3ms/step - loss: 0.5693 - acc: 0.8081 - val_loss: 0.7925 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.78123\n",
      "Epoch 396/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5857 - acc: 0.8000 - val_loss: 0.8007 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.78123\n",
      "Epoch 397/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5423 - acc: 0.8203 - val_loss: 0.8416 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.78123\n",
      "Epoch 398/400\n",
      "4295/4295 [==============================] - 12s 3ms/step - loss: 0.5889 - acc: 0.7958 - val_loss: 0.8203 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.78123\n",
      "Epoch 399/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.6092 - acc: 0.7984 - val_loss: 0.8078 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.78123\n",
      "Epoch 400/400\n",
      "4295/4295 [==============================] - 13s 3ms/step - loss: 0.5455 - acc: 0.8158 - val_loss: 0.7907 - val_acc: 0.7482\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.78123\n",
      "Traing finished.\n",
      "Loading the best model...\n",
      "Best Model loaded!\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# autosave best Model\n",
    "best_model_file = model_fname = os.path.join(original_data_path, 'Models','leafnet.h5')\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "print('Training model...')\n",
    "batch_size = 64\n",
    "epochs = 400\n",
    "model, results = m.train_model(model, images_train, labels_one_hot_train,\n",
    "                             images_val, labels_one_hot_val, \n",
    "                             batch_size, epochs, best_model)\n",
    "print('Traing finished.')\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8515865476589638\n",
      "Test accuracy: 0.7491856679465949\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(images_test, labels_one_hot_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x7fe376588e48>\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(results.history['acc'])\n",
    "plt.plot(results.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid.'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid.'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
