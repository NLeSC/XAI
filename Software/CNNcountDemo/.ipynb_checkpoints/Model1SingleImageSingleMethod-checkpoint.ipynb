{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single analyser of Model1 on single image using iNNvestigate\n",
    "\n",
    "## Circular shapes with same radius\n",
    "\n",
    "This notebook shows how saliency maps are computed for a single method on the Shape Images dataset.\n",
    "\n",
    "(It is based on the **iNNvestigate** notebook: [Introduction](https://github.com/albermax/innvestigate/blob/master/examples/notebooks/introduction.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils_mnist.py\")\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs\n",
    "\n",
    "#import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Load the dataset and keep some images from the test set for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (circle) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of test data:  (6000, 64, 64, 1) and labels:  (6000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "same_shape_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/circles_same_radius_60k.npz\"\n",
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3\n",
    "\n",
    "# load the set of images with the same type and same radius and split to train and test subsets\n",
    "if os.path.isfile(same_shape_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (circle) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, _, images_test, labels_train, _, labels_test = si.load_split_data(same_shape_same_radius_fname)\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of test data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (circle) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") \n",
    "    \n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Load my pretrained CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from CNNcount import model_count_shapes as mcs\n",
    "# filename for model saving\n",
    "same_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_circles_same_radius.h5\"\n",
    "# load the trained model\n",
    "from keras.models import load_model\n",
    "model = load_model(same_shape_same_radius_model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "labels_test shape: (6000, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "numerical_labels_test = labels_test\n",
    "labels_test = np_utils.to_categorical(numerical_labels_test-1, num_classes=None)\n",
    "print(labels_test)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate 10 random images and predict the number of shapes using the trained model\n",
    "for i in range(10):\n",
    "    n = int(np.random.randint(1, 3+1))\n",
    "    shapes = [(0, 4) for _ in range(n)]\n",
    "    img = si.generate_image(64, shapes, 0)    \n",
    "    \n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img,cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    predictions = model.predict(X);\n",
    "    #print(predictions)\n",
    "    pred = np.argmax(predictions) + 1 # we subtracted 1 before\n",
    "    #print(pred)\n",
    "    plt.title('n=%d nÌ‚=%d' % (n, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose a random test image to generate a heatmap for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nim = len(labels_test)\n",
    "ind=int(np.random.randint(1,nim))\n",
    "img=images_test[ind,:,:]\n",
    "img=np.reshape(img,(64,64))\n",
    "label=numerical_labels_test[ind]\n",
    "plt.imshow(img,cmap='binary')\n",
    "plt.title('ind=%d n=%d' % (ind,label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PatternNet Analyzer\n",
    "\n",
    "Show the output in respect to the all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer exists. Loading...\n",
      "PatternNet\n",
      "{}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-125b957c2680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatternNet_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneuron_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \"\"\"\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatternNet_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m# Displaying the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'seismic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/analyzer/base.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, X, neuron_selection)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_analyzer_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_analyzer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/analyzer/base.py\u001b[0m in \u001b[0;36mcreate_analyzer_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         tmp = self._create_analysis(\n\u001b[0;32m--> 414\u001b[0;31m             model, stop_analysis_at_tensors=stop_analysis_at_tensors)\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/analyzer/pattern_based.py\u001b[0m in \u001b[0;36m_create_analysis\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m         )\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPatternNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     def _fit_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/analyzer/base.py\u001b[0m in \u001b[0;36m_create_analysis\u001b[0;34m(self, model, stop_analysis_at_tensors)\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mstop_analysis_at_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_analysis_at_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             return_all_reversed_tensors=return_all_reversed_tensors)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_all_reversed_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/analyzer/base.py\u001b[0m in \u001b[0;36m_reverse_model\u001b[0;34m(self, model, stop_analysis_at_tensors, return_all_reversed_tensors)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mclip_all_reversed_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_clip_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mproject_bottleneck_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_project_bottleneck_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             return_all_reversed_tensors=return_all_reversed_tensors)\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_analysis_at_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/utils/keras/graph.py\u001b[0m in \u001b[0;36mreverse_model\u001b[0;34m(model, reverse_mappings, default_reverse_mapping, head_mapping, stop_mapping_at_tensors, verbose, return_all_reversed_tensors, clip_all_reversed_tensors, project_bottleneck_tensors, execution_trace, reapply_on_copied_layers)\u001b[0m\n\u001b[1;32m    972\u001b[0m                     {\n\u001b[1;32m    973\u001b[0m                         \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                         \u001b[0;34m\"layer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m                     }\n\u001b[1;32m    976\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/analyzer/pattern_based.py\u001b[0m in \u001b[0;36mcreate_kernel_layer_mapping\u001b[0;34m(layer, state)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Apply the pattern mapping on all layers that contain a kernel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcreate_kernel_layer_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_pattern_for_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mmapping_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatternNetReverseKernelLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/innvestigate/analyzer/pattern_based.py\u001b[0m in \u001b[0;36m_get_pattern_for_layer\u001b[0;34m(self, layer, state)\u001b[0m\n\u001b[1;32m    181\u001b[0m                   if kchecks.contains_kernel(l)]\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_patterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#%%pixie_debugger\n",
    "\n",
    "# Stripping the softmax activation from the model\n",
    "model_wo_sm = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "image = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "\n",
    "# Creating another attribution analyzer and set neuron_selection_mode to \"index\"\n",
    "#path to saved analyzers\n",
    "path_to_analyzers = \"/home/elena/eStep/XAI/Data/CountingShapes/Analyzers\"\n",
    "fname = os.path.join(path_to_analyzers, 'pattern.net1.npz')\n",
    "\n",
    "#PatternNet_analyzer = innvestigate.create_analyzer(\"pattern.net\", model_wo_sm, pattern_type = \"relu\", neuron_selection_mode=\"index\")\n",
    "PatternNet_analyzer = innvestigate.create_analyzer(\"pattern.net\", model_wo_sm, pattern_type = \"relu\")\n",
    "\n",
    "if os.path.isfile(fname):\n",
    "    print(\"Analyzer exists. Loading...\")\n",
    "    PatternNet_analyzer.load_npz(fname)\n",
    "else:\n",
    "    print(\"Analyzer doesn't exist. Training and [Saving]...\")\n",
    "    # Some analyzers require training.\n",
    "    PatternNet_analyzer.fit(images_train, batch_size=200, verbose=1)\n",
    "    PatternNet_analyzer.save_npz(fname)\n",
    "\"\"\"    \n",
    "for neuron_index in range(num_classes):\n",
    "    print(\"Analysis w.r.t. to class\", neuron_index+1)\n",
    "    # Applying the analyzer and pass that we want \n",
    "    analysis = PatternNet_analyzer.analyze(image, neuron_index)\n",
    "\"\"\"\n",
    "PatternNet_analyzer.load_npz(fname)\n",
    "analysis = PatternNet_analyzer.analyze(image)\n",
    "# Displaying the gradient\n",
    "plt.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
