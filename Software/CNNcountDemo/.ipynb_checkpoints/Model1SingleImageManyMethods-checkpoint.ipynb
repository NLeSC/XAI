{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple analysers of Model1 on single image using iNNvestigate\n",
    "\n",
    "## Circular shapes with same radius\n",
    "\n",
    "This notebook shows how saliency maps are computed for (the 9 out of all) methods supported by the **iNNvestigate** explainability toolbox on a single test image from the Shape Images dataset. (It is based on the notebook: [MNIST Neuron Selection](https://github.com/albermax/innvestigate/blob/master/examples/notebooks/mnist_neuron_selection.ipynb)). There are errors when trying ot run the remaining 5 methods.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if(K.tensorflow_backend):\n",
    "    import tensorflow as tf\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "mnistutils = imp.load_source(\"utils_mnist\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils_mnist.py\")\n",
    "eutils = imp.load_source(\"utils\", \"/home/elena/eStep/XAI/Software/innvestigate/examples/utils.py\")\n",
    "\n",
    "from CNNcount import shape_images as si\n",
    "from CNNcount import model_count_shapes as mcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Load the dataset and split to train and test set for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file containing images of the same shape (circle) with same radius already exist!\n",
      "Size of training data:  (42000, 64, 64, 1) and labels:  (42000,)\n",
      "Size of test data:  (6000, 64, 64, 1) and labels:  (6000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input image dimensions and number of classes\n",
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 3\n",
    "\n",
    "# filename for loading the data from the NPZ files (NumPy compressed)\n",
    "dataset = 'circles_same_radius'\n",
    "same_shape_same_radius_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/\" + dataset + \"_60k.npz\"\n",
    "\n",
    "\n",
    "# load the set of images with the same type and same radius and split to train and test subsets\n",
    "if os.path.isfile(same_shape_same_radius_fname): # already generated- just load\n",
    "    print (\"The file containing images of the same shape (circle) with same radius already exist!\")\n",
    "    # load from NPZ file for display\n",
    "    images_train, _, images_test, labels_train, _, labels_test = si.load_split_data(same_shape_same_radius_fname)\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        images_train = images_train.reshape(images_train.shape[0], 1, img_rows, img_cols)\n",
    "        images_test = images_test.reshape(images_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "    print(\"Size of training data: \", np.shape(images_train), \"and labels: \", np.shape(labels_train))\n",
    "    print(\"Size of test data: \", np.shape(images_test), \"and labels: \", np.shape(labels_test))\n",
    "else: # missing data\n",
    "    print (\"The file containing images of the same shape (circle) with same radius does not exist!\")\n",
    "    print(\"Use the GenerateShapeImages notebook to generate the experimental data.\") \n",
    "    \n",
    "# plot random 12 of the train images\n",
    "si.plot_12images(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "The next part evaluates the pretrained CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# filename for model saving\n",
    "same_shape_same_radius_model_fname = \"/home/elena/eStep/XAI/Data/CountingShapes/model_circles_same_radius.h5\"\n",
    "# load the trained model\n",
    "\n",
    "model = load_model(same_shape_same_radius_model_fname) \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "labels_test shape: (6000, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "numerical_labels_test = labels_test\n",
    "labels_test = np_utils.to_categorical(numerical_labels_test-1, num_classes=None)\n",
    "print(labels_test)\n",
    "print('labels_test shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(images_test, labels_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 random images and predict the number of shapes using the trained model\n",
    "for i in range(10):\n",
    "    n = int(np.random.randint(1, 3+1))\n",
    "    shapes = [(0, 4) for _ in range(n)]\n",
    "    img = si.generate_image(64, shapes, 0)    \n",
    "    \n",
    "    X = img[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img,cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    predictions = model.predict(X);\n",
    "    #print(predictions)\n",
    "    pred = np.argmax(predictions) + 1 # we subtracted 1 before\n",
    "    #print(pred)\n",
    "    plt.title('n=%d nÌ‚=%d' % (n, pred))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose a random test image to generate a heatmap for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = len(labels_test)\n",
    "ind=int(np.random.randint(1,nim))\n",
    "img=images_test[ind,:,:]\n",
    "img=np.reshape(img,(64,64))\n",
    "label=numerical_labels_test[ind]\n",
    "plt.imshow(img,cmap='binary')\n",
    "plt.title('ind=%d n=%d' % (ind,label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of analysis methods by preparing tuples containing the methods' string identifiers used by innvestigate.analyzer.create_analyzer(...), some optional parameters, a post processing choice for visualizing the computed analysis and a title for the figure to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_range = [0, 1]\n",
    "preprocess, revert_preprocessing = mnistutils.create_preprocessing_f(images_test, input_range)\n",
    "def input_postprocessing(X):\n",
    "    #return revert_preprocessing(X) / 255\n",
    "    return 1-X\n",
    "\n",
    "\n",
    "noise_scale = (input_range[1]-input_range[0]) * 0.1\n",
    "ri = input_range[0]  # reference input\n",
    "\n",
    "# Configure analysis methods and properties\n",
    "methods = [\n",
    "    # NAME            OPT.PARAMS                POSTPROC FXN               TITLE\n",
    "\n",
    "    # Show input\n",
    "    (\"input\",         {},                       input_postprocessing,      \"Input\"),\n",
    "\n",
    "    # Signal\n",
    "    (\"deconvnet\",             {},                       mnistutils.bk_proj,        \"Deconvnet\"),\n",
    "    (\"guided_backprop\",       {},                       mnistutils.bk_proj,        \"Guided Backprop\",),\n",
    "    (\"pattern.net\",   {\"pattern_type\": \"relu\"}, mnistutils.bk_proj,        \"PatternNet\"), \n",
    "\n",
    "    # Function\n",
    "#    (\"gradient\",     {\"postprocess\": \"abs\"},   mnistutils.graymap,        \"Gradient\"),\n",
    "#   (\"smoothgrad\",    {\"noise_scale\": noise_scale,\"postprocess\": \"square\"},mnistutils.graymap,        \"SmoothGrad\"),\n",
    "\n",
    "    # Interaction\n",
    "    (\"pattern.attribution\",  {\"pattern_type\": \"relu\"}, mnistutils.heatmap,        \"PatternAttribution\"),\n",
    "     \n",
    "    \n",
    "   (\"deep_taylor.bounded\",   {\"low\": input_range[0],\"high\": input_range[1]}, mnistutils.heatmap,        \"DeepTaylor\"),\n",
    "    (\"input_t_gradient\",     {},                        mnistutils.heatmap,        \"Input * Gradient\"),\n",
    "    (\"integrated_gradients\", {\"reference_inputs\": ri},  mnistutils.heatmap,        \"Integrated Gradients\"), \n",
    "#    (\"deep_lift.wrapper\",     {\"reference_inputs\": ri}, mnistutils.heatmap,        \"DeepLIFT Wrapper - Rescale\"),\n",
    "#                                                        mnistutils.heatmap,        \"DeepLIFT Wrapper - RevealCancel\"),\n",
    "    (\"lrp.z\",                {},                        mnistutils.heatmap,        \"LRP-Z\"),\n",
    "#    (\"lrp.epsilon\",           {\"epsilon\": 1},           mnistutils.heatmap,        \"LRP-Epsilon\"), \n",
    "]\n",
    "    \n",
    "print('Considered number of explainability methods:', len(methods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop instantiates the analyzer objects based on the loaded/trained model and the analyzers' parameterizations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create model without trailing softmax\n",
    "model_wo_softmax = iutils.keras.graph.model_wo_softmax(model)\n",
    "\n",
    "path_to_analyzers = \"/home/elena/eStep/XAI/Data/CountingShapes/Analyzers/\" + dataset \n",
    "\n",
    "\n",
    "# Create analyzers.\n",
    "analyzers = []\n",
    "for method in methods:\n",
    "    fname = os.path.join(path_to_analyzers, method[0]+'.npz')\n",
    "    \n",
    "    analyzer = innvestigate.create_analyzer(method[0],        # analysis method identifier\n",
    "                                            model_wo_softmax, # model without softmax output\n",
    "                                            neuron_selection_mode=\"index\",\n",
    "                                            **method[1])     \n",
    "    \n",
    "    if os.path.isfile(fname) :\n",
    "        print(\"Analyzer\", method[0], \"exists! Loading...\")\n",
    "        analyzer = analyzer.load_npz(fname)\n",
    "    else:\n",
    "        print(\"Analyzer\", method[0], \" doesn't exist! Creating and possibly Training and [Saving]...\")\n",
    "        # Some analyzers require training.\n",
    "        analyzer.fit(images_train, batch_size=256, verbose=1)\n",
    "        if (method[0]=='pattern.net') or (method[0]=='pattern.attribution'):\n",
    "            analyzer.save_npz(fname)\n",
    "    \n",
    "    analyzers.append(analyzer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the image with the different analyzers on all output neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_image = list(zip(images_test[ind-1:ind], numerical_labels_test[ind-1:ind]-1))\n",
    "label_to_class_name = [str(i+1) for i in range(num_classes)]\n",
    "\n",
    "for image_nr, (x, y) in enumerate(test_image):\n",
    "    # Add batch axis.\n",
    "    x = x[None, :, :, :]\n",
    "\n",
    "    analysis = np.zeros([num_classes, len(analyzers), 64, 64, 3])\n",
    "    text = []\n",
    "\n",
    "    for ii, output_neuron in enumerate([0, 1, 2]):\n",
    "        # Predict final activations, probabilites, and label.\n",
    "        presm = model_wo_softmax.predict_on_batch(x)[0]\n",
    "        prob = model.predict_on_batch(x)[0]\n",
    "        y_hat = prob.argmax()\n",
    "\n",
    "        # Save prediction info:\n",
    "        text.append((\"%s\" % label_to_class_name[y],    # ground truth label\n",
    "                     \"%.2f\" % presm[output_neuron],    # pre-softmax logits\n",
    "                     \"%.2f\" % prob[output_neuron],     # probabilistic softmax output  \n",
    "                     \"%s\" % label_to_class_name[output_neuron]\n",
    "                    ))\n",
    "       \n",
    "\n",
    "        for aidx, analyzer in enumerate(analyzers):\n",
    "            print(\"Analyzing with analyzer \", analyzer)\n",
    "            # Analyze.\n",
    "            a = analyzer.analyze(x, neuron_selection=output_neuron)\n",
    "\n",
    "            # Apply common postprocessing, e.g., re-ordering the channels for plotting.\n",
    "            a = mnistutils.postprocess(a)\n",
    "            # Apply analysis postprocessing, e.g., creating a heatmap.\n",
    "            a = methods[aidx][2](a)\n",
    "            # Store the analysis.\n",
    "            analysis[ii, aidx] = a[0]\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Image nr. {}: \".format(image_nr))\n",
    "    # Prepare the grid as rectengular list\n",
    "    grid = [[analysis[i, j] for j in range(analysis.shape[1])]\n",
    "            for i in range(analysis.shape[0])]\n",
    "    # Prepare the labels\n",
    "    label, presm, prob, pred = zip(*text)\n",
    "    print(label)\n",
    "    row_labels_left = [('label: {}'.format(label[i]), 'neuron: {}'.format(pred[i])) for i in range(len(label))]\n",
    "    row_labels_right = [('logit: {}'.format(presm[i]), 'prob: {}'.format(prob[i])) for i in range(len(label))]\n",
    "    col_labels = [''.join(method[3]) for method in methods]\n",
    "\n",
    "    # Plot the analysis.\n",
    "    file_name = os.environ.get(\"PLOTFILENAME\", None)\n",
    "    if file_name is not None:\n",
    "        file_name = \".\".join(file_name.split(\".\")[:-1])+(\"_%i\" % output_neuron)+file_name.split(\".\")[-1]\n",
    "    eutils.plot_image_grid(grid, row_labels_left, row_labels_right, col_labels, file_name=file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
